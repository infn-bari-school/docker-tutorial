{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>The main goal of this tutorial is to learn the docker basic concepts from a user perspective and to get familiar with the docker cli.</p> <p>You will learn about:</p> <ul> <li>how docker stores images and manages container data</li> <li>how to run your first container</li> <li>how to run a service in a docker container and make it available outside of Docker</li> <li>how to persist your data</li> <li>how to install and use a docker web interface </li> <li>how to create (e.g. from a Dockerfile) or modify a docker image and share it using a registry</li> <li>how to setup a basic CI pipeline to automate the image build</li> </ul>"},{"location":"compose/concepts/","title":"Concepts","text":"<p>Docker Compose is a utility designed to define and execute multi-container Docker applications. It facilitates the management of interconnected containers as a unified entity</p>"},{"location":"compose/concepts/#docker-compose-file","title":"Docker compose file","text":"<p>Docker uses a simple YAML file to describe multi-container application.</p> <p>This file is called a \"docker-compose file\"</p> <p>Following a simple example of a docker compose file:</p> <pre><code>services:\n  db:\n    image: influxdb:2.7\n    volumes:\n    - db_data:/var/lib/influxdb2:rw\n    ports:\n    - \"8086:8086\"\n    networks:\n    - db_net\n\nvolumes:\n  db_data:\n\nnetworks:\n  db_net:\n</code></pre> <p>In the YAML file you can notice an basic structure:</p> <ul> <li>the services keyword let you list all services of the application.</li> <li>db is the arbitraty name of the service,  it can be anything you like as long as it's unique.</li> <li>inside each service, with the image, volumes, ports and networks keywords you can configure the execution of the service</li> <li>the volumes keyword allows to define volumes to be attach in the containers. </li> <li>the networks keyword allows to define networks to be used in the containers. </li> </ul>"},{"location":"compose/concepts/#docker-compose-cli","title":"Docker compose CLI","text":"<p>The Docker CLI lets you interact with your Docker Compose applications through the <code>docker compose</code> command, and its subcommands. </p> <p>Using the CLI, you can manage the lifecycle of your multi-container applications defined in the compose.yaml file.</p> <p>The CLI commands enable you to start, stop, and configure your applications effortlessly.</p> <ul> <li>docker compose up: initializes and starts the application environment</li> <li>docker compose start: starts the application environment</li> <li>docker compose restart: restarts the already created application environment</li> <li>docker compose stop: stops the application environment</li> <li>docker compose down: stops and destroys the application environment</li> </ul>"},{"location":"compose/concepts/#most-used-docker-compose-commands","title":"Most used docker compose commands","text":"<ul> <li><code>docker compose up</code>: initializes, starts the application environment and shows logs without return to command line</li> <li><code>docker compose up -d</code>: initializes and starts the application environment in detacted mode</li> <li><code>docker compose ps</code>: lists the running containers/services</li> <li><code>docker compose down -v</code>: stops and destroys the application environment and volumes</li> <li><code>docker compose logs</code>: shows application logs</li> </ul>"},{"location":"compose/concepts/#start-your-first-multi-container-application","title":"Start your first multi-container application","text":"<p>Let's start a multi-container application. At this point it's not important the content of the docker compose file.</p> <p>Docker compose file:</p> <pre><code>services:\n  db:\n    image: influxdb:2.7\n    volumes:\n    - db_data:/var/lib/influxdb2:rw\n    ports:\n    - \"8086:8086\"\n    networks:\n    - db_net\n\nvolumes:\n  db_data:\n\nnetworks:\n  db_net:\n</code></pre> <p>Commands:</p> <pre><code>user@vm:~/prova_1$ docker compose up -d\n\u2714 db 10 layers [\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff\u28ff]     0B/0B   Pulled 39.4s                              \n[+] Running 3/3\n\u2714 Network prova_1_db_net    Created                                                                                                                 \n\u2714 Volume \"prova_1_db_data\"  Created                                                                                                                \n\u2714 Container prova_1-db-1    Started \n\nuser@vm:~/prova_1$ docker container ps\nCONTAINERID   IMAGE          NAMES\nBe72e5..      influxdb:2.7     prova_1_db_1\n\nuser@vm:~/prova_1$ docker volume ls\nDRIVER  VOLUME NAME\nlocal   46f4a..\nlocal   prova_1_db_data\n\nuser@vm:~/prova_1$ docker network ls\nNETWORK ID  NAME              DRIVER    SCOPE\n51039c996454   bridge             bridge    local\n85ffa41af96f   host               host      local\nd6f329122060   none               null      local\nec31eefd60d5   prova_1_db_net   bridge  local\n</code></pre> <p>Tip</p> <p>Every object name (image, volume and network) starts with <code>prova_1</code> that represents the folder name containing the docker compose file. </p>"},{"location":"compose/concepts/#stop-your-first-multi-container-application","title":"Stop your first multi-container application","text":"<p>Commands:</p> <pre><code>user@vm:~/prova_1$ docker compose down\n[+] Running 2/2\n \u2714 Container prova_1-db-1  Removed                                                                                                                \n \u2714 Network prova_1_db_net  Removed\n\nuser@vm:~/prova_1$ docker container ps\nCONTAINERID   IMAGE          STATUS          NAMES\n\nuser@vm:~/prova_1$ docker volume ls\nDRIVER  VOLUME NAME\nlocal   46f4..\nlocal   prova_1_db_data\n\nuser@vm:~/prova_1$ docker network ls\nNETWORK ID  NAME    DRIVER  SCOPE\n51039c996454   bridge   bridge  local\n85ffa41af96f   host     host    local\nd6f329122060   none     null    local\n</code></pre> <p>Some comments: - Volumes are not removed with <code>docker compose down</code> - Compose preserves all volumes used by your services - Data inside volume is not lost and can be reused once the application is restarted - To remove volume as well, use <code>docker compose down --volumes</code> or <code>docker compose down -v</code></p>"},{"location":"compose/concepts/#project-name","title":"Project name","text":"<p>Compose uses project names to isolate multi-container applications from each others.</p> <p>If not set, the folder name is taken as project name.</p> <p>Tip</p> <p>A custom project name can be set using the <code>-p</code> command line option or the <code>COMPOSE_PROJECT_NAME</code> environment variable.</p> <pre><code>user@vm:~$ cd ..\nuser@vm:~$ cp -r prova_1/ prova_2/\nuser@vm:~$ cd prova_2\n\nuser@vm:~/prova_2$ docker compose up -d\n[+] Running 3/3\n\u2714 Network prova_2_db_net   Created\n\u2714 Volume \"prova_2_db_data\" Created\n\u2714 Container prova_2-db-1   Started\n\nuser@vm:~/prova_2$ docker ps\nCONTAINERID     IMAGE           NAMES\n297f44..        influxdb:2.7    prova_2_db_1\n\nuser@vm:~/prova_2$ docker compose down\n[+] Running 2/2\n\u2714 Container prova_2-db-1 Removed\n\u2714 Network prova_2_db_net Removed\n</code></pre>"},{"location":"compose/concepts/#custom-network-configuration","title":"Custom Network configuration","text":"<p>By default Compose sets up a single network for your application.</p> <p>Each container joins the default network and is both reachable by other containers on that network and discoverable by them at a hostname identical to the container name.</p> <p>If you make a con\ufb01guration change to a service and run <code>docker compose up</code> to update it, the old container is removed and the new one joins the network under a different IP address but the same name. So it is suggested to use hostnames instead of IPs to connect services.</p> <p>You can specify your custom network with the top-level networks key. Following an example.</p> <pre><code>networks:\n  front:\n    driver: bridge\n    driver_opts:\n      com.docker.network.enable_ipv6: \"true\"\n    ipam:\n      driver: default\n      config:\n        - subnet: 172.16.238.0/24\n        gateway: 172.16.238.1\n        - subnet: \"2001:3984:3989::/64\"\n        gateway: \"2001:3984:3989::1\"\n</code></pre>"},{"location":"compose/concepts/#write-your-first-docker-compose-file","title":"Write your first docker compose file","text":"<p>Let's learn how to write a docker compose file by converting an application described from command line instructions to the corresponding YAML format file.</p> <pre><code>docker volume create influxdb-storage\nexport INFLUXDB_USERNAME=corsodocker2024\nexport INFLUXDB_PW=corsodocker2024\ndocker container run --name influxdb \\\n  -p 8086:8086 \\\n  -v influxdb-storage:/var/lib/influxdb \\\n  -e DOCKER_INFLUXDB_INIT_MODE=setup \\\n  -e DOCKER_INFLUXDB_INIT_USERNAME=${INFLUXDB_USERNAME} \\\n  -e DOCKER_INFLUXDB_INIT_PASSWORD=${INFLUXDB_PW} \\\n  -e DOCKER_INFLUXDB_INIT_ORG=INFN \\\n  -e DOCKER_INFLUXDB_INIT_BUCKET=INFN-BUCKET \\\n  influxdb:2.7\n\ndocker volume create grafana-storage\nexport GRAFANA_USERNAME=corsodocker2024\nexport GRAFANA_PW=corsodocker2024\ndocker container run --name grafana \\\n  -p 3000:3000 \\\n  -v grafana-storage:/var/lib/grafana \\\n  -e GF_SECURITY_ADMIN_USER=${GRAFANA_USERNAME} \\\n  -e GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PW} \\\n  grafana/grafana:11.2.0-ubuntu\n</code></pre> <p>The resulting YAML file is:</p> <pre><code>services:\n  influxdb:\n    image: influxdb:2.7\n    ports:\n      - '8086:8086'\n    networks:\n      - my_net\n    volumes:\n      - influxdb-storage:/var/lib/influxdb\n    environment:\n      - DOCKER_INFLUXDB_INIT_MODE=setup\n      - DOCKER_INFLUXDB_INIT_USERNAME=${INFLUXDB_USERNAME}\n      - DOCKER_INFLUXDB_INIT_PASSWORD=${INFLUXDB_PW}\n      - DOCKER_INFLUXDB_INIT_ORG=INFN\n      - DOCKER_INFLUXDB_INIT_BUCKET=INFN-BUCKET\n\n  grafana:\n    image: grafana/grafana:11.2.0-ubuntu\n    ports:\n      - '3000:3000'\n    networks:\n      - my_net\n    volumes:\n      - grafana-storage:/var/lib/grafana\n    environment:\n      - GF_SECURITY_ADMIN_USER=${GRAFANA_USERNAME}\n      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PW} \n\nvolumes:\n  influxdb-storage: {}\n  grafana-storage: {}\n\nnetworks:\n  my_net: {}\n</code></pre> <p>As you can see, there is a one-to-one correspondence between information in the command line instructions and the docker compose file.</p>"},{"location":"compose/concepts/#using-default-network-definition","title":"Using default network definition","text":"<p>Docker Compose creates a default network if not present any network definitions in the docker compose file. In such a case, the section <code>networks</code> inside each application should be avoided as well. In this second scenario, the YAML file become: </p> <pre><code>services:\n  influxdb:\n    image: influxdb:2.7\n    ports:\n      - '8086:8086'\n    volumes:\n      - influxdb-storage:/var/lib/influxdb\n    environment:\n      - DOCKER_INFLUXDB_INIT_MODE=setup\n      - DOCKER_INFLUXDB_INIT_USERNAME=${INFLUXDB_USERNAME}\n      - DOCKER_INFLUXDB_INIT_PASSWORD=${INFLUXDB_PW}\n      - DOCKER_INFLUXDB_INIT_ORG=INFN\n      - DOCKER_INFLUXDB_INIT_BUCKET=INFN-BUCKET\n  grafana:\n    image: grafana/grafana:11.2.0-ubuntu\n    ports:\n      - '3000:3000'\n    volumes:\n      - grafana-storage:/var/lib/grafana\n    environment:\n      - GF_SECURITY_ADMIN_USER=${GRAFANA_USERNAME}\n      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PW} \n\nvolumes:\n  influxdb-storage: {}\n  grafana-storage: {}\n</code></pre>"},{"location":"compose/concepts/#environment-variable-definition","title":"Environment variable definition","text":"<p>As you can see from the docker compose file above, the environment variable values are inserted directly inside the YAML file. This could be unacceplable in some cases.</p> <p>A second approach allows to link existed environment variables by inserting their names inside the docker compose file.</p> <pre><code>services:\n  influxdb:\n    image: influxdb:2.7\n    ports:\n      - '8086:8086'\n    volumes:\n      - influxdb-storage:/var/lib/influxdb\n    environment:\n      - DOCKER_INFLUXDB_INIT_MODE=setup\n      - DOCKER_INFLUXDB_INIT_USERNAME=${INFLUXDB_USERNAME}\n      - DOCKER_INFLUXDB_INIT_PASSWORD=${INFLUXDB_PW}\n      - DOCKER_INFLUXDB_INIT_ORG=INFN\n      - DOCKER_INFLUXDB_INIT_BUCKET=INFN-BUCKET\n\n  grafana:\n    image: grafana/grafana:11.2.0-ubuntu\n    ports:\n      - '3000:3000'\n    volumes:\n      - grafana-storage:/var/lib/grafana\n    environment:\n      - GF_SECURITY_ADMIN_USER=${GRAFANA_USERNAME}\n      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PW}\n\nvolumes:\n  influxdb-storage: {}\n  grafana-storage: {}\n</code></pre> <p>The above multi-container application can be started with the following commands:</p> <pre><code>export INFLUXDB_USERNAME=corsodocker2024\nexport INFLUXDB_PW=corsodocker2024\nexport GRAFANA_USERNAME=admin\nexport GRAFANA_PW=admin\ndocker compose up \n</code></pre> <p>Or write a further file containing all environment variables. This file must be named <code>.env</code>. </p> <pre><code>user@vm:~/example$ cat .env\nINFLUXDB_USERNAME=corsodocker2024\nINFLUXDB_PW=corsodocker2024\nGRAFANA_USERNAME=corsodocker2024\nGRAFANA_PW=corsodocker2024\n</code></pre> <p>Docker checks if in the directory is present a <code>.env</code> file. In a such a case, it will import the environment variables when the multi-container application is started.</p> <p>A third approach involves defining an environment variable file per service and inserting its name within the service definition, as show below.</p> <p>Environment variable files' content:</p> <pre><code>user@vm:~/example$ cat influxdb.env\nDOCKER_INFLUXDB_INIT_MODE=setup\nDOCKER_INFLUXDB_INIT_USERNAME=corsodocker2024\nDOCKER_INFLUXDB_INIT_PASSWORD=corsodocker2024\nDOCKER_INFLUXDB_INIT_ORG=INFN\nDOCKER_INFLUXDB_INIT_BUCKET=INFN-BUCKET\n\nuser@vm:~/example$ cat grafana.env\nGF_SECURITY_ADMIN_USER=corsodocker2024\nGF_SECURITY_ADMIN_PASSWORD=corsodocker2024\n</code></pre> <p>Docker compose file:</p> <pre><code>services:\n  influxdb:\n    image: influxdb:2.7\n    ports:\n      - '8086:8086'\n    volumes:\n      - influxdb-storage:/var/lib/influxdb\n    env_file:\n      - influxdb.env\n\n  grafana:\n    image: grafana/grafana:11.2.0-ubuntu\n    ports:\n      - '3000:3000'\n    volumes:\n      - grafana-storage:/var/lib/grafana\n    env_file:\n      - grafana.env\n\nvolumes:\n  influxdb-storage: {}\n  grafana-storage: {}\n</code></pre>"},{"location":"compose/concepts/#further-comments","title":"Further comments","text":"<p>Environment variables offer a flexible way to customize your application. For example, you can use them to specify the image version of a service:</p> <pre><code>service:\n  influxdb:\n    image: influxdb:{$INFLUX_VERSION}\n</code></pre> <p>Default values are allowed:</p> <pre><code>service:\n  influxdb:\n    image: influxdb:{$INFLUX_VERSION:-2.7}\n</code></pre> <p>The default value should be placed after the <code>:-</code> characters.</p> <p>Since more approaches are supported, Docker compose uses the following priority order, overwriting the less important with the higher ones:</p> <p>When multiple approaches are used, Docker compose prioritizes configuration as follows, with high-priority values overriding lower-priority ones:</p> <ol> <li> <p>Compose \ufb01le (highest important)</p> </li> <li> <p>Shell environment variables</p> </li> <li> <p>Environment \ufb01le</p> </li> <li> <p>Docker\ufb01le</p> </li> <li> <p>Undefined variables (lowest important)</p> </li> </ol>"},{"location":"compose/concepts/#health-checks","title":"Health checks","text":"<p>Similar to the command-line interface, you can specify health checks for services within a Docker Compose file, as demonstrated below.</p> <pre><code>docker volume create influxdb-storage\nexport INFLUXDB_USERNAME=admin\nexport INFLUXDB_PW=admin\ndocker container run --name influxdb \n           -p 8086:8086 \\ \n           -v influxdb-storage:/var/lib/influxdb \\\n           -e DOCKER_INFLUXDB_INIT_MODE=setup \\\n           -e DOCKER_INFLUXDB_INIT_USERNAME=${INFLUXDB_USERNAME} \\\n           -e DOCKER_INFLUXDB_INIT_PASSWORD=${INFLUXDB_PW} \\\n           -e DOCKER_INFLUXDB_INIT_ORG=INFN \\\n           -e DOCKER_INFLUXDB_INIT_BUCKET=INFN-BUCKET \\\n           --health-cmd='curl -f http://localhost:8086||exit 1' \\\n           --health-start-period=30s \\\n           --health-interval= 30s \\\n           --health-timeout=10s \\\n           --health-retries=4 \\\n           influxdb:2.7\n</code></pre> <p>Docker compose file:</p> <pre><code>services:\n  influxdb:\n    image: influxdb:2.7\n    ports:\n      - '8086:8086'\n    volumes:\n    - influxdb-storage:/var/lib/influxdb\n    environment:\n      - DOCKER_INFLUXDB_INIT_MODE=setup\n      - DOCKER_INFLUXDB_INIT_USERNAME=${INFLUXDB_USERNAME}\n      - DOCKER_INFLUXDB_INIT_PASSWORD=${INFLUXDB_PW}\n      - DOCKER_INFLUXDB_INIT_ORG=INFN\n      - DOCKER_INFLUXDB_INIT_BUCKET=INFN-BUCKET\n    healthcheck:\n      test: \"curl --fail http://localhost:8086 || exit 1\"\n      start_period: 30s\n      interval: 30s\n      timeout: 10s\n      retries: 4\n</code></pre>"},{"location":"compose/concepts/#dependencies","title":"Dependencies","text":"<p>Applications often have dependencies between services, requiring some to start before others. </p> <p>Docker Compose uses the <code>depends_on</code> keyword to define these dependencies. </p> <p>For instance, we can configure Grafana to start only after InfluxDB is running.</p> <p>The Docker Compose file becomes:</p> <pre><code>services:\n  influxdb:\n    image: influxdb:2.7\n    ports:\n      - '8086:8086'\n    volumes:\n      - influxdb-storage:/var/lib/influxdb\n    environment:\n      - DOCKER_INFLUXDB_INIT_MODE=setup\n      - DOCKER_INFLUXDB_INIT_USERNAME=${INFLUXDB_USERNAME}\n      - DOCKER_INFLUXDB_INIT_PASSWORD=${INFLUXDB_PW}\n      - DOCKER_INFLUXDB_INIT_ORG=INFN\n      - DOCKER_INFLUXDB_INIT_BUCKET=INFN-BUCKET\n\n  grafana:\n    image: grafana/grafana:11.2.0-ubuntu\n    ports:\n      - '3000:3000'\n    volumes:\n      - grafana-storage:/var/lib/grafana\n    environment:\n      - GF_SECURITY_ADMIN_USER=${GRAFANA_USERNAME}\n      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}\n    depends_on:\n      - influxdb\n\nvolumes:\n  influxdb-storage:\n  grafana-storage:\n</code></pre>"},{"location":"compose/concepts/#waiting-for-a-service-is-ready","title":"Waiting for a service is ready","text":"<p>Certain applications require tools to be fully functional, not just running. Health checks can determine when a tool is ready for use.</p> <p>The Docker compose file becomes:</p> <pre><code>services:\n  influxdb:\n    image: influxdb:2.7\n    ports:\n      - '8086:8086'\n    volumes:\n      - influxdb-storage:/var/lib/influxdb\n    environment:\n      - DOCKER_INFLUXDB_INIT_MODE=setup\n      - DOCKER_INFLUXDB_INIT_USERNAME=${INFLUXDB_USERNAME}\n      - DOCKER_INFLUXDB_INIT_PASSWORD=${INFLUXDB_PW}\n      - DOCKER_INFLUXDB_INIT_ORG=INFN\n      - DOCKER_INFLUXDB_INIT_BUCKET=INFN-BUCKET\n    healthcheck:\n      test: \"curl --fail http://localhost:8086 || exit 1\"\n      start_period: 30s\n      interval: 30s\n      timeout: 10s\n      retries: 4\n\n  grafana:\n    image: grafana/grafana:11.2.0-ubuntu\n    ... \n    depends_on:\n      influxdb:\n        condition: service_healthy\n</code></pre>"},{"location":"compose/concepts/#profiles","title":"Profiles","text":"<p>Profiles in Docker Compose offer a way to tailor your application for different scenarios by selectively activating or deactivating services. </p> <p>You can assign services to zero or more profiles. </p> <p>Unassigned services always start, while assigned ones start only when their corresponding profile is active.</p> <p>Let's considering the following Docker compose file</p> <pre><code>services:\n  frontend:\n    image: frontend\n    profiles: \n      - frontend\n\n  phpmyadmin:\n    image: phpmyadmin\n    depends_on:\n      - db\n    profiles:\n      - debug\n\n  backend:\n    image: backend\n\n  db:\n    image: mysql\n</code></pre> <p>Tip</p> <ul> <li>the <code>db</code> service is always started since it does not contain the <code>profile</code> keyword</li> <li>the <code>phpmyadmin</code> service is started only when the <code>debug</code> profile is enabled</li> <li>the <code>frontend</code> service is started only when the <code>frontend</code> profile is enabled</li> </ul> <p>Examples:</p> <pre><code>docker compose up                                     # Only the db service is started\ndocker compose --profile frontend up                  # Only the db and frontend services are started\nCOMPOSE_PROFILES=frontend docker compose up           # Other syntax for the above command\n\ndocker compose --profile frontend --profile debug up  # All services are started\nCOMPOSE_PROFILES=frontend,debug docker compose up     # Other syntax for the above command\n</code></pre>"},{"location":"compose/concepts/#build-dockerfile-and-run-a-multi-container-application","title":"Build Dockerfile and run a multi-container application","text":"<p>Within the image section of each service, Docker Compose defines the image used. </p> <p>You can specify a custom image built at runtime using a Dockerfile. </p> <p>Replace the <code>image</code> keyword with <code>build</code> for such services. </p> <p>Here's an example of a single-service application using a custom <code>python:3</code> image.</p> <p>Folder content:</p> <pre><code>user@vm:~/prova_4$ ls -l\nDockerfile\nrequirements\ndocker-compose.yml\nmy-script.py\n</code></pre> <p>Dockerfile file content:</p> <pre><code>FROM python:3\n\nCOPY requirements /requirements\nRUN pip install -r requirements\nCOPY my-script.py /my-script.py\n\nCMD [ \"python3\", \"/my-script.py\"]\n</code></pre> <p>Requirements file content:</p> <pre><code>pandas\nnumpy\n</code></pre> <p>my-script file content: </p> <pre><code>import socket\nimport sys\nfrom time import sleep\nsock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\nserver_address = ('localhost', 1234)\nprint(f'starting up on {server_address[0]} port {server_address[1]}')\nsock.bind(server_address)\nsleep(60)\n</code></pre> <p>Docker compose file content:</p> <pre><code>services:\n  my_service:\n    build: .\n    ports:\n      - '1234:1234'\n    volumes:\n      - dir_data:/data\n</code></pre>"},{"location":"compose/concepts/#lets-start-the-application","title":"Let's start the application:","text":"<p>Tip</p> <ul> <li>using the  <code>--build</code> option forces Docker to rebuild the image</li> </ul> CommandOutput <pre><code>docker compose up -d --build\n</code></pre> <pre><code>Creating network \"prova_4_default\" with the default driver\nBuilding my_service\nSending build context to Docker daemon   5.12kB\nStep 1/4 : FROM python:3\n---&gt; de529ffbdb66\nStep 2/4 : COPY requirements ./\n---&gt; 8f6840fe4dab\nStep 3/4 : RUN pip install --no-cache-dir -r requirements.txt\n---&gt; Running in 363ffa40779c\nCollecting pandas\nDownloading pandas-1.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.7 MB)\nCollecting numpy\nDownloading numpy-1.22.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.8 MB)\nCollecting python-dateutil&gt;=2.8.1\nDownloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\nCollecting pytz&gt;=2020.1\nDownloading pytz-2021.3-py2.py3-none-any.whl (503 kB)\nCollecting six&gt;=1.5\nDownloading six-1.16.0-py2.py3-none-any.whl (11 kB)\nInstalling collected packages: six, pytz, python-dateutil, numpy, pandas\nSuccessfully installed numpy-1.22.2 pandas-1.4.0 python-dateutil-2.8.2 pytz-2021.3 six-1.16.0\nRemoving intermediate container 363ffa40779c\n---&gt; 79f0ed627dd6\nStep 4/4 : CMD [ \"python3\", \"/my-script.py\" ]\n---&gt; Running in 4f45fc08e6df\nRemoving intermediate container 4f45fc08e6df\n---&gt; 4fd169b43c5f\nSuccessfully built 4fd169b43c5f\nSuccessfully tagged prova_4_my_service:latest\nCreating prova_4_my_service_1 ... done\n</code></pre>"},{"location":"compose/hands-on/","title":"Hands-on","text":""},{"location":"compose/hands-on/#hands-on-1","title":"Hands-on 1","text":"<p>Write the compose.yaml file for the following Docker CLI inserting the <code>depends_on</code> condition on db health check</p> Exercise detailsSolution <pre><code>docker network create wordpress_net\ndocker volume create db_data\ndocker volume create wp_data\ndocker container run --name db \\\n  --network wordpress_net \\\n  -v db_data:/var/lib/mysql \\\n  -e MYSQL_ROOT_PASSWORD=somewordpress \\\n  -e MYSQL_USER=wordpress_user \\\n  -e MYSQL_PASSWORD=wordpress_password \\\n  -e MYSQL_DATABASE=wordpress_database \\\n  --restart always \\\n  --health-cmd=\"mysqladmin ping --silent\" \\\n  --health-interval=10s \\\n  --health-start-period=10s \\\n  --health-timeout=10s \\\n  --health-retries=60 \\\n  --restart always \\\n  -d \\\n  mariadb:10.6.4-focal\n\ndocker run --name wp \\\n  --network wordpress_net \\\n  -v wp_data:/var/www/html \\\n  -p 8080:80 \\\n  -e WORDPRESS_DB_HOST=db \\\n  -e WORDPRESS_DB_USER=wordpress_user \\\n  -e WORDPRESS_DB_PASSWORD=wordpress_password \\\n  -e WORDPRESS_DB_NAME=wordpress_database \\\n  -d \\\n  wordpress\n</code></pre> <pre><code>services:\n  db:\n    image: mariadb:10.6.4-focal\n    volumes:\n      - db_data:/var/lib/mysql\n    environment:\n      - MYSQL_ROOT_PASSWORD=somewordpress\n      - MYSQL_USER=wordpress_user\n      - MYSQL_PASSWORD=wordpress_password\n      - MYSQL_DATABASE=wordpress_database\n    restart: always\n    healthcheck:\n      test: \"mysqladmin ping --silent\"\n      interval: 10s\n      start_period: 10s\n      timeout: 10s\n      retries: 60\n\n  wp:\n    image: wordpress:latest\n    volumes:\n      - wp_data:/var/www/html\n    ports:\n      - 8080:80\n    environment:\n      - WORDPRESS_DB_HOST=db\n      - WORDPRESS_DB_USER=wordpress_user\n      - WORDPRESS_DB_PASSWORD=wordpress_password\n      - WORDPRESS_DB_NAME=wordpress_database\n    restart: always\n    depends_on:\n      db:\n        condition: service_healthy\n\nvolumes:\n  db_data:\n  wp_data:\n</code></pre>"},{"location":"compose/hands-on/#hands-on-2","title":"Hands-on 2","text":"<p>Write the compose.yaml file that builds the following Dockerfile and uses it</p> Exercise detailsSolution 1Solution 2Solution 3 <p><pre><code>base-image: jupyter/minimal-notebook\npython module to install: pandas, numpy\nexpose port: 8888\ncommand: /opt/conda/bin/python3.11 /opt/conda/bin/jupyter-lab \\\n            --no-browser \\\n            --allow-root \\\n            --NotebookApp.token='' \\\n            --NotebookApp.password=''\n</code></pre> Jupyter notebook to test the configuration</p> <pre><code>import pandas as pd\noutput_path = 'my_output.csv'\n\ndata = {\n    'apples': [3, 2, 0, 1], \n    'oranges': [0, 3, 7, 2]\n}\ndf = pd.DataFrame(data)\n\ndf.to_csv(output_path)\n</code></pre> <pre><code>cat &gt; requirements.txt &lt;&lt; EOF\npandas\nnumpy\nEOF\n\ncat &gt; Dockerfile &lt;&lt; EOF\nFROM jupyter/minimal-notebook\nCOPY requirements.txt /requirements.txt\nRUN pip install -r /requirements.txt\nEOF\n\ncat &gt; compose.yaml &lt;&lt; EOF\nservices:\n  my_jupyter:\n    build: .\n    ports:\n      - 8888:8888\n    command: /opt/conda/bin/python3.11 /opt/conda/bin/jupyter-lab --no-browser --allow-root --NotebookApp.token='' --NotebookApp.password=''\nEOF\n\n# To execute the application run:\n# docker compose up\n</code></pre> <pre><code>cat &gt; requirements.txt &lt;&lt; EOF\npandas\nnumpy\nEOF\n\ncat &gt; Dockerfile &lt;&lt; EOF\nFROM jupyter/minimal-notebook\nCOPY requirements.txt /requirements.txt\nRUN pip install -r /requirements.txt\nEOF\n\ncat &gt; compose.yaml &lt;&lt; EOF\nservices:\n  my_jupyter:\n    build: .\n    ports:\n      - 8888:8888\n    command: \"/opt/conda/bin/python3.11 \\\n              /opt/conda/bin/jupyter-lab \\\n                --no-browser \\\n                --allow-root \\\n                --NotebookApp.token='' \\\n                --NotebookApp.password='' \"\nEOF\n\n# To execute the application run:\n# docker compose up\n</code></pre> <pre><code>cat &gt; requirements.txt &lt;&lt; EOF\npandas\nnumpy\nEOF\n\ncat &gt; Dockerfile &lt;&lt; EOF\nFROM jupyter/minimal-notebook\nCOPY requirements.txt /requirements.txt\nRUN pip install -r /requirements.txt\nEOF\n\ncat &gt; compose.yaml &lt;&lt; EOF\nservices:\n  my_jupyter:\n    build: .\n    ports:\n      - 8888:8888\n    command: \n      - /opt/conda/bin/python3.11\n      - /opt/conda/bin/jupyter-lab\n      - --no-browser\n      - --allow-root\n      - --NotebookApp.token=''\n      - --NotebookApp.password=''\nEOF\n\n# To execute the application run:\n# docker compose up\n</code></pre>"},{"location":"container/env_vars/","title":"How to pass env variables to a container","text":"<p>An environment variable consists of a variable name and its value.</p> <p>There are two ways to set environment variables for a docker container: with CLI arguments, using an env file.</p>"},{"location":"container/env_vars/#cli-arguments","title":"CLI arguments","text":"<p>When we launch our Docker container, we can pass environment variables as key-value pairs directly into the command line using the parameter \u2013env (or its short form -e).</p> <p>For instance, let's execute the following command:</p> <pre><code>docker run --rm --env VARIABLE1=foobar alpine env\n</code></pre> <p>Tip</p> <p>Docker Alpine is the \u201cDockerized\u201d version of Alpine Linux, a Linux distribution known for being exceptionally lightweight and secure. For these reasons and others, Docker Alpine is a popular choice for developers looking for a base image on which to create their own containerized apps.</p> <p>The environment variables we set will be printed to the console:</p> <pre><code>...\nVARIABLE1=foobar\n</code></pre> <p>As can be seen, the Docker container correctly interprets the variable <code>VARIABLE1</code>.</p> <p>Also, we can omit the value in the command line if the variable already exists in the local environment.</p> <p>For example, let's define a local environment variable:</p> <pre><code>export VARIABLE2=foobar2\n</code></pre> <p>Then, let's specify the environment variable without its value:</p> <pre><code>docker run --rm --env VARIABLE2 alpine env\n</code></pre> <p>And we can see Docker still picked up the value, this time from the surrounding environment:</p> <pre><code>...\nVARIABLE2=foobar2\n</code></pre>"},{"location":"container/env_vars/#using-env-file","title":"Using --env-file","text":"<p>The above solution is adequate when the number of variables is low. However, as soon as we have more than a handful of variables, it can quickly become cumbersome and error-prone.</p> <p>An alternative solution is to use a text file to store our variables, using the standard key=value format.</p> <p>Let's define a few variables in a file we'll call my-env.txt:</p> <pre><code>echo VARIABLE1=foobar1 &gt; my-env.txt\necho VARIABLE2=foobar2 &gt;&gt; my-env.txt\necho VARIABLE3=foobar3 &gt;&gt; my-env.txt\n</code></pre> <p>Now, let's inject this file into our Docker container:</p> <pre><code>docker run --env-file my-env.txt alpine env\n</code></pre> <p>Finally, let's take a look at the output:</p> <pre><code>...\nVARIABLE1=foobar1\nVARIABLE2=foobar2\nVARIABLE3=foobar3\n</code></pre>"},{"location":"container/example/","title":"Run a dockerized service","text":""},{"location":"container/example/#run-a-basic-http-server-in-a-docker-container","title":"Run a basic http server in a docker container","text":"<p>Let's deploy a simple web server using <code>nginx</code>. First of all, let's search on Docker Hub for an already available image.</p> <p>We can use the <code>search</code> command as follows:</p> <pre><code>docker search nginx\n</code></pre> <p>You will get something like the following output:</p> <pre><code>NAME                              DESCRIPTION                                     STARS     OFFICIAL\nnginx                             Official build of Nginx.                        20157     [OK]\nnginx/nginx-quic-qns              NGINX QUIC interop                              1\nnginx/nginx-ingress               NGINX and  NGINX Plus Ingress Controllers fo\u2026   94\nnginx/nginx-ingress-operator      NGINX Ingress Operator for NGINX and NGINX P\u2026   2\nnginx/nginx-prometheus-exporter   NGINX Prometheus Exporter for NGINX and NGIN\u2026   43\nnginx/unit                        This repository is retired, use the Docker o\u2026   63\nnginx/unit-preview                Unit preview features                           0\nbitnami/nginx                     Bitnami container image for NGINX               193\nrapidfort/nginx                   RapidFort optimized, hardened image for NGINX   15\nkasmweb/nginx                     An Nginx image based off nginx:alpine and in\u2026   8\nubuntu/nginx                      Nginx, a high-performance reverse proxy &amp; we\u2026   116\nchainguard/nginx                  Minimal Wolfi-based nginx HTTP, reverse prox\u2026   2\ndockette/nginx                    Nginx SSL / HSTS / HTTP2                        3\njitesoft/nginx                    Nginx on alpine linux                           0\ndocksal/nginx                     Nginx service image for Docksal                 0\ngluufederation/nginx               A customized NGINX image containing a consu\u2026   1\nokteto/nginx                                                                      0\nobjectscale/nginx                                                                 0\nintel/nginx                                                                       0\ncircleci/nginx                    This image is for internal use                  2\nbitnamicharts/nginx                                                               0\nvmware/nginx                                                                      2\nrancher/nginx                                                                     2\nlinuxserver/nginx                 An Nginx container, brought to you by LinuxS\u2026   217\nredash/nginx                      Pre-configured nginx to proxy linked contain\u2026   2\n</code></pre> <p>Tip</p> <p>The <code>docker search</code> command returns the following image information:</p> <ul> <li>Repository names</li> <li>Image descriptions</li> <li>Stars - these measure the popularity of an image</li> <li>Official - an image managed by the upstream developer (e.g., the fedora image managed by the Fedora team) </li> <li>Automated - an image built by the Docker Hub's Automated Build process</li> </ul> <p>In alternative, you can make a similar search on the Docker Hub Web site:</p> <p></p> <p>Let's download the official image using the <code>docker image pull</code> command:</p> <pre><code>docker image pull nginx\n</code></pre> <pre><code>Using default tag: latest\nlatest: Pulling from library/nginx\ne4fff0779e6d: Pull complete\n2a0cb278fd9f: Pull complete\n7045d6c32ae2: Pull complete\n03de31afb035: Pull complete\n0f17be8dcff2: Pull complete\n14b7e5e8f394: Pull complete\n23fa5a7b99a6: Pull complete\nDigest: sha256:447a8665cc1dab95b1ca778e162215839ccbb9189104c79d7ec3a81e14577add\nStatus: Downloaded newer image for nginx:latest\ndocker.io/library/nginx:latest\n</code></pre> <p>In order to list the images downloaded on your host, you can use the command:</p> <p><pre><code>docker image ls \n</code></pre> The output of this command provides useful information, including the size of the image:</p> <pre><code>REPOSITORY    TAG       IMAGE ID       CREATED         SIZE\nnginx         latest    5ef79149e0ec   2 weeks ago     188MB\nubuntu        latest    edbfe74c41f8   4 weeks ago     78.1MB\nhello-world   latest    d2c94e258dcb   16 months ago   13.3kB\n</code></pre> <p>Let's have a look at the image with the commands we have already seen in the previous section:</p> <pre><code>docker image inspect nginx\n</code></pre> <pre><code>[\n    {\n        \"Id\": \"sha256:5ef79149e0ec84a7a9f9284c3f91aa3c20608f8391f5445eabe92ef07dbda03c\",\n        \"RepoTags\": [\n            \"nginx:latest\"\n        ],\n        \"RepoDigests\": [\n            \"nginx@sha256:447a8665cc1dab95b1ca778e162215839ccbb9189104c79d7ec3a81e14577add\"\n        ],\n        \"Parent\": \"\",\n        \"Comment\": \"buildkit.dockerfile.v0\",\n        \"Created\": \"2024-08-14T21:31:12Z\",\n        \"DockerVersion\": \"\",\n        \"Author\": \"\",\n        \"Config\": {\n            \"Hostname\": \"\",\n            \"Domainname\": \"\",\n            \"User\": \"\",\n            \"AttachStdin\": false,\n            \"AttachStdout\": false,\n            \"AttachStderr\": false,\n            \"ExposedPorts\": {\n                \"80/tcp\": {}\n            },\n            \"Tty\": false,\n            \"OpenStdin\": false,\n            \"StdinOnce\": false,\n            \"Env\": [\n                \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\n                \"NGINX_VERSION=1.27.1\",\n                \"NJS_VERSION=0.8.5\",\n                \"NJS_RELEASE=1~bookworm\",\n                \"PKG_RELEASE=1~bookworm\",\n                \"DYNPKG_RELEASE=2~bookworm\"\n            ],\n            \"Cmd\": [\n                \"nginx\",\n                \"-g\",\n                \"daemon off;\"\n            ],\n            \"ArgsEscaped\": true,\n            \"Image\": \"\",\n            \"Volumes\": null,\n            \"WorkingDir\": \"\",\n            \"Entrypoint\": [\n                \"/docker-entrypoint.sh\"\n            ],\n            \"OnBuild\": null,\n            \"Labels\": {\n                \"maintainer\": \"NGINX Docker Maintainers &lt;docker-maint@nginx.com&gt;\"\n            },\n            \"StopSignal\": \"SIGQUIT\"\n        },\n        \"Architecture\": \"amd64\",\n        \"Os\": \"linux\",\n        \"Size\": 187694648,\n        \"GraphDriver\": {\n            \"Data\": {\n                \"LowerDir\": \"/var/lib/docker/overlay2/29bfd1646b549c5a2e7488cd2df0cfbf5b31e6e452390a6419590f798a5be2b7/diff:/var/lib/docker/overlay2/b9732ca651e6793c280fe0b6408bbebe59bbbebbdd596b40cfd51f469243892a/diff:/var/lib/docker/overlay2/2e84243b34f95d37bd725e031f33665c8a2ec89d99824bcb96a0694a52dcb7c9/diff:/var/lib/docker/overlay2/4d59513c75c18791768dc9a21232185999d0fa81c65506e950842b46565fb20b/diff:/var/lib/docker/overlay2/4bd3dd2794ec1e9f2729f9252882a1728abbd44a2e417feb55fbd019857d7054/diff:/var/lib/docker/overlay2/9145ec71e543c915530869f33be035a9f64642f304aa39acdd73b64d6d667d48/diff\",\n                \"MergedDir\": \"/var/lib/docker/overlay2/670ced786458f0d0102c989a939e8808fdfd0e8c982c70d6173b7d7b36fe9e9d/merged\",\n                \"UpperDir\": \"/var/lib/docker/overlay2/670ced786458f0d0102c989a939e8808fdfd0e8c982c70d6173b7d7b36fe9e9d/diff\",\n                \"WorkDir\": \"/var/lib/docker/overlay2/670ced786458f0d0102c989a939e8808fdfd0e8c982c70d6173b7d7b36fe9e9d/work\"\n            },\n            \"Name\": \"overlay2\"\n        },\n        \"RootFS\": {\n            \"Type\": \"layers\",\n            \"Layers\": [\n                \"sha256:9853575bc4f955c5892dd64187538a6cd02dba6968eba9201854876a7a257034\",\n                \"sha256:72db5db515fdd9ae82b759fc207fdfbcc31567c28bb87950abc94ce1d60b2d40\",\n                \"sha256:8b87c0c6652495401acfbe029ede84a5f327664770561ba5f8b7fe9149f52dd0\",\n                \"sha256:ec1a2ca4ac8784def146544fc7068db06a188d2da4fd7c4e134a76415b8bc1a8\",\n                \"sha256:55e54df86207fa772302a6fc1e78eb60bd7e3ebd4f913ef7f5ad668ad69ab64d\",\n                \"sha256:f4f00eaedec7933a48b09f3948c685c41d55f0bf5906295dd022c05b65082344\",\n                \"sha256:5f0272c6e96d5cd8ea1c6507cfce81980d4b99322bd037d99250a79d4c0b9f1a\"\n            ]\n        },\n        \"Metadata\": {\n            \"LastTagTime\": \"0001-01-01T00:00:00Z\"\n        }\n    }\n]\n</code></pre> <p>We can see that the nginx version in our container will be <code>1.27.1</code>, the service will be listening on port <code>80</code> and the command that will be executed at the container start is <code>nginx -g daemon off;</code>.</p> <p>This is a useful exercise, but in general you will find these information in the description of the image on Docker hub.</p>"},{"location":"container/example/#creating-a-daemonized-container","title":"Creating a daemonized container","text":"<p>In addition to the interactive containers, we can create longer-running containers. </p> <p>Daemonized containers don't have the interactive session we've used in our previous example and are ideal for running applications and services.  Most of the containers you're likely to run will probably be daemonized. </p> <p>Let's start a daemonized container now.</p> <pre><code>docker container run -d --name nginx nginx\n</code></pre> <p>Note</p> <p>The <code>-d</code> flag tells Docker to detach the container to the background. The <code>--name</code> option allows to set a name for your container</p> <p>Instead of being attached to a shell, the <code>docker run</code> command has instead returned a container ID and returned us to our command prompt. </p> <p>We can see our container running with:</p> <pre><code>docker container ps\n</code></pre> <pre><code>docker container ps\nCONTAINER ID   IMAGE     COMMAND                  CREATED          STATUS          PORTS     NAMES\n43147119c02a   nginx     \"/docker-entrypoint.\u2026\"   20 seconds ago   Up 12 seconds   80/tcp    nginx\n</code></pre>"},{"location":"container/example/#getting-the-container-log","title":"Getting the container log","text":"<p>What's happening inside our container? We can use the <code>docker container logs</code> command to fetch the log of a container:</p> <pre><code>docker container logs nginx\n</code></pre> <pre><code>/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration\n/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh\n10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf\n10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf\n/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh\n/docker-entrypoint.sh: Configuration complete; ready for start up\n2024/09/04 14:09:50 [notice] 1#1: using the \"epoll\" event method\n2024/09/04 14:09:50 [notice] 1#1: nginx/1.27.1\n2024/09/04 14:09:50 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14)\n2024/09/04 14:09:50 [notice] 1#1: OS: Linux 6.8.0-40-generic\n2024/09/04 14:09:50 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1048576:1048576\n2024/09/04 14:09:50 [notice] 1#1: start worker processes\n2024/09/04 14:09:50 [notice] 1#1: start worker process 29\n2024/09/04 14:09:50 [notice] 1#1: start worker process 30\n</code></pre> <p>Tip</p> <p>We can also monitor the container's logs much like the <code>tail -f</code> binary operates using the <code>-f</code> flag. You can also tail a portion of the logs of a container by using the <code>--tail</code> option. Moreover you can also use the <code>-t</code> flag to prefix the log entries with timestamps.</p>"},{"location":"container/example/#inspecting-the-container-processes","title":"Inspecting the container processes","text":"<p>We can inspect the processes running inside our container using the <code>docker container top</code> command:</p> <pre><code>docker container top nginx\nUID                 PID                 PPID                C                   STIME               TTY                 TIME                CMD\nroot                49252               49232               0                   14:09               ?                   00:00:00            nginx: master process nginx -g daemon off;\nmessage+            49301               49252               0                   14:09               ?                   00:00:00            nginx: worker process\nmessage+            49302               49252               0                   14:09               ?                   00:00:00            nginx: worker process\n</code></pre>"},{"location":"container/example/#finding-out-more-about-our-container","title":"Finding out more about our container","text":"<p>Let's use again the command <code>docker container inspect</code> to get more information about our container:</p> commandOutput <pre><code>docker container inspect nginx\n</code></pre> <pre><code>[\n    {\n        \"Id\": \"43147119c02a544cffcc2e99a2bd634b6fcec63406e4d9ac510821f5cf140e60\",\n        \"Created\": \"2024-09-04T14:09:42.284257833Z\",\n        \"Path\": \"/docker-entrypoint.sh\",\n        \"Args\": [\n            \"nginx\",\n            \"-g\",\n            \"daemon off;\"\n        ],\n        \"State\": {\n            \"Status\": \"running\",\n            \"Running\": true,\n            \"Paused\": false,\n            \"Restarting\": false,\n            \"OOMKilled\": false,\n            \"Dead\": false,\n            \"Pid\": 49252,\n            \"ExitCode\": 0,\n            \"Error\": \"\",\n            \"StartedAt\": \"2024-09-04T14:09:49.261329401Z\",\n            \"FinishedAt\": \"0001-01-01T00:00:00Z\"\n        },\n        \"Image\": \"sha256:5ef79149e0ec84a7a9f9284c3f91aa3c20608f8391f5445eabe92ef07dbda03c\",\n        \"ResolvConfPath\": \"/var/lib/docker/containers/43147119c02a544cffcc2e99a2bd634b6fcec63406e4d9ac510821f5cf140e60/resolv.conf\",\n        \"HostnamePath\": \"/var/lib/docker/containers/43147119c02a544cffcc2e99a2bd634b6fcec63406e4d9ac510821f5cf140e60/hostname\",\n        \"HostsPath\": \"/var/lib/docker/containers/43147119c02a544cffcc2e99a2bd634b6fcec63406e4d9ac510821f5cf140e60/hosts\",\n        \"LogPath\": \"/var/lib/docker/containers/43147119c02a544cffcc2e99a2bd634b6fcec63406e4d9ac510821f5cf140e60/43147119c02a544cffcc2e99a2bd634b6fcec63406e4d9ac510821f5cf140e60-json.log\",\n        \"Name\": \"/nginx\",\n        \"RestartCount\": 0,\n        \"Driver\": \"overlay2\",\n        \"Platform\": \"linux\",\n        \"MountLabel\": \"\",\n        \"ProcessLabel\": \"\",\n        \"AppArmorProfile\": \"docker-default\",\n        \"ExecIDs\": null,\n        \"HostConfig\": {\n            \"Binds\": null,\n            \"ContainerIDFile\": \"\",\n            \"LogConfig\": {\n                \"Type\": \"json-file\",\n                \"Config\": {}\n            },\n            \"NetworkMode\": \"bridge\",\n            \"PortBindings\": {},\n            \"RestartPolicy\": {\n                \"Name\": \"no\",\n                \"MaximumRetryCount\": 0\n            },\n            \"AutoRemove\": false,\n            \"VolumeDriver\": \"\",\n            \"VolumesFrom\": null,\n            \"ConsoleSize\": [\n                39,\n                178\n            ],\n            \"CapAdd\": null,\n            \"CapDrop\": null,\n            \"CgroupnsMode\": \"private\",\n            \"Dns\": [],\n            \"DnsOptions\": [],\n            \"DnsSearch\": [],\n            \"ExtraHosts\": null,\n            \"GroupAdd\": null,\n            \"IpcMode\": \"private\",\n            \"Cgroup\": \"\",\n            \"Links\": null,\n            \"OomScoreAdj\": 0,\n            \"PidMode\": \"\",\n            \"Privileged\": false,\n            \"PublishAllPorts\": false,\n            \"ReadonlyRootfs\": false,\n            \"SecurityOpt\": null,\n            \"UTSMode\": \"\",\n            \"UsernsMode\": \"\",\n            \"ShmSize\": 67108864,\n            \"Runtime\": \"runc\",\n            \"Isolation\": \"\",\n            \"CpuShares\": 0,\n            \"Memory\": 0,\n            \"NanoCpus\": 0,\n            \"CgroupParent\": \"\",\n            \"BlkioWeight\": 0,\n            \"BlkioWeightDevice\": [],\n            \"BlkioDeviceReadBps\": [],\n            \"BlkioDeviceWriteBps\": [],\n            \"BlkioDeviceReadIOps\": [],\n            \"BlkioDeviceWriteIOps\": [],\n            \"CpuPeriod\": 0,\n            \"CpuQuota\": 0,\n            \"CpuRealtimePeriod\": 0,\n            \"CpuRealtimeRuntime\": 0,\n            \"CpusetCpus\": \"\",\n            \"CpusetMems\": \"\",\n            \"Devices\": [],\n            \"DeviceCgroupRules\": null,\n            \"DeviceRequests\": null,\n            \"MemoryReservation\": 0,\n            \"MemorySwap\": 0,\n            \"MemorySwappiness\": null,\n            \"OomKillDisable\": null,\n            \"PidsLimit\": null,\n            \"Ulimits\": [],\n            \"CpuCount\": 0,\n            \"CpuPercent\": 0,\n            \"IOMaximumIOps\": 0,\n            \"IOMaximumBandwidth\": 0,\n            \"MaskedPaths\": [\n                \"/proc/asound\",\n                \"/proc/acpi\",\n                \"/proc/kcore\",\n                \"/proc/keys\",\n                \"/proc/latency_stats\",\n                \"/proc/timer_list\",\n                \"/proc/timer_stats\",\n                \"/proc/sched_debug\",\n                \"/proc/scsi\",\n                \"/sys/firmware\",\n                \"/sys/devices/virtual/powercap\"\n            ],\n            \"ReadonlyPaths\": [\n                \"/proc/bus\",\n                \"/proc/fs\",\n                \"/proc/irq\",\n                \"/proc/sys\",\n                \"/proc/sysrq-trigger\"\n            ]\n        },\n        \"GraphDriver\": {\n            \"Data\": {\n                \"LowerDir\": \"/var/lib/docker/overlay2/2439f7d82ca5c505d4b56fde68aa78ba7caf71b3ca2cf1598dddff528566a964-init/diff:/var/lib/docker/overlay2/670ced786458f0d0102c989a939e8808fdfd0e8c982c70d6173b7d7b36fe9e9d/diff:/var/lib/docker/overlay2/29bfd1646b549c5a2e7488cd2df0cfbf5b31e6e452390a6419590f798a5be2b7/diff:/var/lib/docker/overlay2/b9732ca651e6793c280fe0b6408bbebe59bbbebbdd596b40cfd51f469243892a/diff:/var/lib/docker/overlay2/2e84243b34f95d37bd725e031f33665c8a2ec89d99824bcb96a0694a52dcb7c9/diff:/var/lib/docker/overlay2/4d59513c75c18791768dc9a21232185999d0fa81c65506e950842b46565fb20b/diff:/var/lib/docker/overlay2/4bd3dd2794ec1e9f2729f9252882a1728abbd44a2e417feb55fbd019857d7054/diff:/var/lib/docker/overlay2/9145ec71e543c915530869f33be035a9f64642f304aa39acdd73b64d6d667d48/diff\",\n                \"MergedDir\": \"/var/lib/docker/overlay2/2439f7d82ca5c505d4b56fde68aa78ba7caf71b3ca2cf1598dddff528566a964/merged\",\n                \"UpperDir\": \"/var/lib/docker/overlay2/2439f7d82ca5c505d4b56fde68aa78ba7caf71b3ca2cf1598dddff528566a964/diff\",\n                \"WorkDir\": \"/var/lib/docker/overlay2/2439f7d82ca5c505d4b56fde68aa78ba7caf71b3ca2cf1598dddff528566a964/work\"\n            },\n            \"Name\": \"overlay2\"\n        },\n        \"Mounts\": [],\n        \"Config\": {\n            \"Hostname\": \"43147119c02a\",\n            \"Domainname\": \"\",\n            \"User\": \"\",\n            \"AttachStdin\": false,\n            \"AttachStdout\": false,\n            \"AttachStderr\": false,\n            \"ExposedPorts\": {\n                \"80/tcp\": {}\n            },\n            \"Tty\": false,\n            \"OpenStdin\": false,\n            \"StdinOnce\": false,\n            \"Env\": [\n                \"PATH=/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin\",\n                \"NGINX_VERSION=1.27.1\",\n                \"NJS_VERSION=0.8.5\",\n                \"NJS_RELEASE=1~bookworm\",\n                \"PKG_RELEASE=1~bookworm\",\n                \"DYNPKG_RELEASE=2~bookworm\"\n            ],\n            \"Cmd\": [\n                \"nginx\",\n                \"-g\",\n                \"daemon off;\"\n            ],\n            \"Image\": \"nginx\",\n            \"Volumes\": null,\n            \"WorkingDir\": \"\",\n            \"Entrypoint\": [\n                \"/docker-entrypoint.sh\"\n            ],\n            \"OnBuild\": null,\n            \"Labels\": {\n                \"maintainer\": \"NGINX Docker Maintainers &lt;docker-maint@nginx.com&gt;\"\n            },\n            \"StopSignal\": \"SIGQUIT\"\n        },\n        \"NetworkSettings\": {\n            \"Bridge\": \"\",\n            \"SandboxID\": \"4c76fb8e97c6aca6858a8476d764d259fbebbb97c38b48f6b65a8bd8413eb165\",\n            \"SandboxKey\": \"/var/run/docker/netns/4c76fb8e97c6\",\n            \"Ports\": {\n                \"80/tcp\": null\n            },\n            \"HairpinMode\": false,\n            \"LinkLocalIPv6Address\": \"\",\n            \"LinkLocalIPv6PrefixLen\": 0,\n            \"SecondaryIPAddresses\": null,\n            \"SecondaryIPv6Addresses\": null,\n            \"EndpointID\": \"cbfee38857162451d749c7772167ac9d01c9fb844b76211aa41c0b239b384472\",\n            \"Gateway\": \"172.17.0.1\",\n            \"GlobalIPv6Address\": \"\",\n            \"GlobalIPv6PrefixLen\": 0,\n            \"IPAddress\": \"172.17.0.3\",\n            \"IPPrefixLen\": 16,\n            \"IPv6Gateway\": \"\",\n            \"MacAddress\": \"02:42:ac:11:00:03\",\n            \"Networks\": {\n                \"bridge\": {\n                    \"IPAMConfig\": null,\n                    \"Links\": null,\n                    \"Aliases\": null,\n                    \"MacAddress\": \"02:42:ac:11:00:03\",\n                    \"DriverOpts\": null,\n                    \"NetworkID\": \"b6fbe659163bbccd7ffdace6cfe009584c698941994079fe9f9b3a34d360839c\",\n                    \"EndpointID\": \"cbfee38857162451d749c7772167ac9d01c9fb844b76211aa41c0b239b384472\",\n                    \"Gateway\": \"172.17.0.1\",\n                    \"IPAddress\": \"172.17.0.3\",\n                    \"IPPrefixLen\": 16,\n                    \"IPv6Gateway\": \"\",\n                    \"GlobalIPv6Address\": \"\",\n                    \"GlobalIPv6PrefixLen\": 0,\n                    \"DNSNames\": null\n                }\n            }\n        }\n    }\n]\n</code></pre> <p>We can also selectively query the inspect results hash using the <code>-f</code> or <code>--format</code> flag.</p> <p>For example, let's retrieve the container network address:</p> <pre><code>docker container inspect -f '{{.NetworkSettings.IPAddress}}' nginx\n</code></pre> <pre><code>172.17.0.3\n</code></pre>"},{"location":"container/health_checks/","title":"How to add a health check to your docker container","text":"<p>Health checks (available since Docker 1.12) allow a container to expose its workload\u2019s availability. This stands apart from whether the container is running. If your database goes down, your API server won\u2019t be able to handle requests, even though its Docker container is still running.</p> <p>When a health check command is specified, it tells Docker how to test the container to see if it's working. With no health check specified, Docker has no way of knowing whether or not the services running within your container are actually up or not.</p> <p>Health checks can be configured in different ways:</p> <ul> <li>directly in the docker image (Dockerfile)</li> <li>when you launch your standalone container with <code>docker run</code> (we will cover this case below) or in your docker compose file</li> </ul> <p>In all cases, the health check is configured as a command that the docker daemon will execute every 30 seconds (default interval that can be overriden). Docker uses the command\u2019s exit code to determine your container\u2019s healthiness:</p> <ul> <li>0 \u2013 The container is healthy and working normally.</li> <li>1 \u2013 The container is unhealthy; the workload may not be functioning.</li> <li>2 \u2013 This status code is reserved by Docker and should not be used. </li> </ul> <p>Without health checks, a simple <code>docker ps</code> would report the container as available. Adding a health check extends the <code>docker ps</code> output to include the container\u2019s true state.</p>"},{"location":"container/health_checks/#health-check-configuration","title":"Health Check Configuration","text":"<p>There are a few options that we can use to customize our health check instruction:</p> <ul> <li>interval - DURATION (default: 30s)</li> <li>timeout - DURATION (default: 30s)</li> <li>start-period - DURATION (default: 0s)</li> <li>retries - DURATION (default: 3)</li> </ul> <p>where</p> <ul> <li> <p>interval (option: <code>--health-interval</code>, default: 30s) - specifies the time between the health check for the application container. it waits for the specified time from one check to another.</p> </li> <li> <p>timeout (option: <code>--health-timeout</code>, default: 30s) - specifies the time that the health check waits for a response to consider the status of the container. For example, if we define 30 seconds and our server doesn\u2019t respond within 30 seconds, then it\u2019s considered as failed.</p> </li> <li> <p>start-period (option: <code>--health-start-period</code>, default: 0s) - specifies the number of seconds the container needs to start; health check will wait for that time to start.</p> </li> <li> <p>retries (option: <code>--health-retries</code>, default: 3) - specifies the number of consecutive health check failures required to declare the container status as unhealthy. Health check will only try up to the specified retry number. If the server fails consecutively up to the specified times, it is then considered unhealthy.</p> </li> </ul>"},{"location":"container/health_checks/#example","title":"Example","text":"<p>We will now add a health check to our <code>nginx</code> container: the check will be implemented using <code>curl</code> command <code>curl --fail http://localhost</code>:</p> <pre><code>docker run --name nginx -d --health-cmd='curl --fail http://localhost:80 || exit 1' nginx\n</code></pre> <p>The <code>curl</code> command makes a request to <code>localhost:80</code> and if the request returns the http code 200, it will return exit code 0; otherwise, it will return exit code 1. </p> <p>Look at the container status using <code>docker ps</code>. The container can have three states:</p> <ul> <li>starting \u2013 Initial status when the container is still starting</li> <li>healthy \u2013 If the command succeeds then the container is healthy</li> <li>unhealthy \u2013 If a single run of the command takes longer than the specified timeout then it is considered unhealthy. If a health check fails, retries will be run for the requested number of times and the container status will be declared unhealthy if the check still fails.</li> </ul> <pre><code>CONTAINER ID   IMAGE     COMMAND                  CREATED         STATUS                            PORTS     NAMES\n75beb1db3d27   nginx     \"/docker-entrypoint.\u2026\"   9 seconds ago   Up 3 seconds (health: starting)   80/tcp    nginx\n</code></pre> <p>Initially, it will take some time to start the health check and update, whether the application is healthy or not. After the start period, if the application is healthy you will get:</p> <pre><code>CONTAINER ID   IMAGE     COMMAND                  CREATED          STATUS                    PORTS     NAMES\n75beb1db3d27   nginx     \"/docker-entrypoint.\u2026\"   46 seconds ago   Up 44 seconds (healthy)   80/tcp    nginx\n</code></pre> <p>You can have a look at the container log and see the requests made to check the health status of the application:</p> <p><pre><code>docker logs nginx\n</code></pre> <pre><code>/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration\n/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh\n10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf\n10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf\n/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh\n/docker-entrypoint.sh: Configuration complete; ready for start up\n2023/09/06 06:44:20 [notice] 1#1: using the \"epoll\" event method\n2023/09/06 06:44:20 [notice] 1#1: nginx/1.25.2\n2023/09/06 06:44:20 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14)\n2023/09/06 06:44:20 [notice] 1#1: OS: Linux 5.15.0-82-generic\n2023/09/06 06:44:20 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1048576:1048576\n2023/09/06 06:44:20 [notice] 1#1: start worker processes\n2023/09/06 06:44:20 [notice] 1#1: start worker process 28\n2023/09/06 06:44:20 [notice] 1#1: start worker process 29\n127.0.0.1 - - [06/Sep/2023:06:44:49 +0000] \"GET / HTTP/1.1\" 200 615 \"-\" \"curl/7.88.1\" \"-\"\n127.0.0.1 - - [06/Sep/2023:06:45:20 +0000] \"GET / HTTP/1.1\" 200 615 \"-\" \"curl/7.88.1\" \"-\"\n127.0.0.1 - - [06/Sep/2023:06:45:51 +0000] \"GET / HTTP/1.1\" 200 615 \"-\" \"curl/7.88.1\" \"-\"\n127.0.0.1 - - [06/Sep/2023:06:46:22 +0000] \"GET / HTTP/1.1\" 200 615 \"-\" \"curl/7.88.1\" \"-\"\n127.0.0.1 - - [06/Sep/2023:06:46:53 +0000] \"GET / HTTP/1.1\" 200 615 \"-\" \"curl/7.88.1\" \"-\"\n127.0.0.1 - - [06/Sep/2023:06:47:25 +0000] \"GET / HTTP/1.1\" 200 615 \"-\" \"curl/7.88.1\" \"-\"\n127.0.0.1 - - [06/Sep/2023:06:47:55 +0000] \"GET / HTTP/1.1\" 200 615 \"-\" \"curl/7.88.1\" \"-\"\n</code></pre></p> <p>As you can see, the check runs every 30s (default) but you can change the interval with the option <code>--health-interval</code>.</p> <p>Now let's remove the <code>index.html</code> file that nginx serves on http://localhost in order to simulate an application failure:</p> <pre><code>docker exec nginx sh -c 'mv /usr/share/nginx/html/index.html /usr/share/nginx/html/index.html.1'\n</code></pre> <p>Look again at the log:</p> <pre><code>/docker-entrypoint.sh: /docker-entrypoint.d/ is not empty, will attempt to perform configuration\n/docker-entrypoint.sh: Looking for shell scripts in /docker-entrypoint.d/\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/10-listen-on-ipv6-by-default.sh\n10-listen-on-ipv6-by-default.sh: info: Getting the checksum of /etc/nginx/conf.d/default.conf\n10-listen-on-ipv6-by-default.sh: info: Enabled listen on IPv6 in /etc/nginx/conf.d/default.conf\n/docker-entrypoint.sh: Sourcing /docker-entrypoint.d/15-local-resolvers.envsh\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/20-envsubst-on-templates.sh\n/docker-entrypoint.sh: Launching /docker-entrypoint.d/30-tune-worker-processes.sh\n/docker-entrypoint.sh: Configuration complete; ready for start up\n2023/09/06 06:44:20 [notice] 1#1: using the \"epoll\" event method\n2023/09/06 06:44:20 [notice] 1#1: nginx/1.25.2\n2023/09/06 06:44:20 [notice] 1#1: built by gcc 12.2.0 (Debian 12.2.0-14)\n2023/09/06 06:44:20 [notice] 1#1: OS: Linux 5.15.0-82-generic\n2023/09/06 06:44:20 [notice] 1#1: getrlimit(RLIMIT_NOFILE): 1048576:1048576\n2023/09/06 06:44:20 [notice] 1#1: start worker processes\n2023/09/06 06:44:20 [notice] 1#1: start worker process 28\n2023/09/06 06:44:20 [notice] 1#1: start worker process 29\n127.0.0.1 - - [06/Sep/2023:06:44:49 +0000] \"GET / HTTP/1.1\" 200 615 \"-\" \"curl/7.88.1\" \"-\"\n127.0.0.1 - - [06/Sep/2023:06:45:20 +0000] \"GET / HTTP/1.1\" 200 615 \"-\" \"curl/7.88.1\" \"-\"\n127.0.0.1 - - [06/Sep/2023:06:45:51 +0000] \"GET / HTTP/1.1\" 200 615 \"-\" \"curl/7.88.1\" \"-\"\n127.0.0.1 - - [06/Sep/2023:06:46:22 +0000] \"GET / HTTP/1.1\" 200 615 \"-\" \"curl/7.88.1\" \"-\"\n127.0.0.1 - - [06/Sep/2023:06:46:53 +0000] \"GET / HTTP/1.1\" 200 615 \"-\" \"curl/7.88.1\" \"-\"\n127.0.0.1 - - [06/Sep/2023:06:47:25 +0000] \"GET / HTTP/1.1\" 200 615 \"-\" \"curl/7.88.1\" \"-\"\n127.0.0.1 - - [06/Sep/2023:06:47:55 +0000] \"GET / HTTP/1.1\" 200 615 \"-\" \"curl/7.88.1\" \"-\"\n127.0.0.1 - - [06/Sep/2023:06:48:26 +0000] \"GET / HTTP/1.1\" 200 615 \"-\" \"curl/7.88.1\" \"-\"\n127.0.0.1 - - [06/Sep/2023:06:48:57 +0000] \"GET / HTTP/1.1\" 200 615 \"-\" \"curl/7.88.1\" \"-\"\n2023/09/06 06:49:27 [error] 29#29: *10 directory index of \"/usr/share/nginx/html/\" is forbidden, client: 127.0.0.1, server: localhost, request: \"GET / HTTP/1.1\", host: \"localhost\"\n127.0.0.1 - - [06/Sep/2023:06:49:27 +0000] \"GET / HTTP/1.1\" 403 153 \"-\" \"curl/7.88.1\" \"-\"\n2023/09/06 06:49:58 [error] 29#29: *11 directory index of \"/usr/share/nginx/html/\" is forbidden, client: 127.0.0.1, server: localhost, request: \"GET / HTTP/1.1\", host: \"localhost\"\n127.0.0.1 - - [06/Sep/2023:06:49:58 +0000] \"GET / HTTP/1.1\" 403 153 \"-\" \"curl/7.88.1\" \"-\"\n2023/09/06 06:50:29 [error] 29#29: *12 directory index of \"/usr/share/nginx/html/\" is forbidden, client: 127.0.0.1, server: localhost, request: \"GET / HTTP/1.1\", host: \"localhost\"\n127.0.0.1 - - [06/Sep/2023:06:50:29 +0000] \"GET / HTTP/1.1\" 403 153 \"-\" \"curl/7.88.1\" \"-\"\n</code></pre> <p>The <code>curl</code> command now returns the http error code 403 and therefore the check returns an exit code 1. Check the status of the container with <code>docker ps</code>:</p> <pre><code>CONTAINER ID   IMAGE     COMMAND                  CREATED         STATUS                     PORTS     NAMES\n75beb1db3d27   nginx     \"/docker-entrypoint.\u2026\"   6 minutes ago   Up 6 minutes (unhealthy)   80/tcp    nginx\n</code></pre> <p>The container is flagged as unhealthy after three failures of the check (you can change the number of retries with the option <code>--health-retries</code>).</p> <p>Exercise</p> <p>Restore the <code>index.html</code> file and verify the container status.</p>"},{"location":"container/health_checks/#example-create-a-mariadb-container-configuring-a-custom-health-check-to-check-whether-the-server-is-available","title":"Example: create a MariaDB container configuring a custom health check to check whether the server is available.","text":"<ol> <li> <p>Set the following environment variables with appropriate values for your MySQL configuration:    <pre><code>export MYSQL_USER=...                  # MySQL user (replace with your desired value)\nexport MYSQL_PASSWORD=...              # MySQL user password (replace with your desired value)\nexport MYSQL_ROOT_PASSWORD=...         # MySQL root user password (replace with your desired value)\nexport MYSQL_DATABASE=...              # MySQL database name (replace with your desired value)\n</code></pre></p> </li> <li> <p>Run the container with the custom health check:    <pre><code>docker run -d --name db \\\n  -e MYSQL_DATABASE=${MYSQL_DATABASE} \\\n  -e MYSQL_USER=${MYSQL_USER} \\\n  -e MYSQL_PASSWORD=${MYSQL_PASSWORD} \\\n  -e MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD} \\\n  --health-cmd='mariadb-admin -p${MYSQL_ROOT_PASSWORD} ping -h localhost' \\\n  --health-interval=20s \\\n  --health-retries=3 \\\n  mariadb:latest\n</code></pre></p> </li> </ol> <p>In this command:</p> <ul> <li><code>--name db</code>: Specifies the name of the container as \"db.\"</li> <li><code>-e MYSQL_DATABASE=${MYSQL_DATABASE}</code>: Sets the MySQL database name as an environment variable.</li> <li><code>-e MYSQL_USER=${MYSQL_USER}</code>: Sets the MySQL user as an environment variable.</li> <li><code>-e MYSQL_PASSWORD=${MYSQL_PASSWORD}</code>: Sets the MySQL user's password as an environment variable.</li> <li><code>-e MYSQL_ROOT_PASSWORD=${MYSQL_ROOT_PASSWORD}</code>: Sets the MySQL root user's password as an environment variable.</li> <li><code>--health-cmd</code>: Specifies the custom health check command, which uses the provided MySQL root password to check if the MariaDB server is responsive.</li> <li><code>--health-interval=20s</code>: Sets the health check interval to 20 seconds.</li> <li><code>--health-retries=3</code>: Specifies the number of retries before marking the container as \"unhealthy.\"</li> </ul>"},{"location":"container/health_checks/#lab-challenge","title":"Lab challenge","text":"<p>Goal: create a PostgreSQL container and setup a health check to monitor its status</p> <p>Hints</p> <ul> <li>Search for PostgreSQL official docker image on docker hub</li> <li>Read the documentation and understand how to start your server</li> <li>Specify a simple health check using the tool \"pg_isready\" to check if the server is alive </li> </ul>"},{"location":"container/manipulation/","title":"Work with your first container","text":"<p>If you read the output from our <code>hello world</code>, they even recommend what to try next.</p> <p><pre><code>docker container run -it ubuntu bash\n</code></pre> Let's see what happens:</p> <pre><code>Unable to find image 'ubuntu:latest' locally\nlatest: Pulling from library/ubuntu\n31e907dcc94a: Pull complete\nDigest: sha256:8a37d68f4f73ebf3d4efafbcf66379bf3728902a8038616808f04e34a9ab63ee\nStatus: Downloaded newer image for ubuntu:latest\nroot@0e539c9ccee4:/#\n</code></pre> <p>We are inside the docker container!</p> <p>Tip</p> <p>You need to use the <code>-it</code> option whenever you want to run a container in interactive mode. - The <code>-i</code> or <code>--interactive</code> option connects you to the input stream of the container, so that you can send inputs to bash; - The <code>-t</code> or <code>--tty</code> option makes sure that you get some good formatting and a native terminal-like experience by allocating a pseudo-tty. </p>"},{"location":"container/manipulation/#playing-with-a-running-container","title":"Playing with a running container","text":"<p>This is a fully fledged Ubuntu host, and we can do anything we like in it. Let's explore it a bit, starting with asking for its hostname:</p> <pre><code>root@0e539c9ccee4:/# hostname\n0e539c9ccee4\n</code></pre> <p>Tip</p> <p>A container's hostname defaults to be the container's ID in Docker. You can override the hostname using <code>--hostname</code>.</p> <p>Let's have a look at the <code>/etc/hosts</code> file too. <pre><code>root@0e539c9ccee4:/# cat /etc/hosts\n127.0.0.1   localhost\n::1 localhost ip6-localhost ip6-loopback\nfe00::0 ip6-localnet\nff00::0 ip6-mcastprefix\nff02::1 ip6-allnodes\nff02::2 ip6-allrouters\n172.17.0.2  0e539c9ccee4\n</code></pre> Docker has also added a host entry for our container with its IP address. Let's also check out its networking configuration.</p> <pre><code>root@0e539c9ccee4:/# ip a\n1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n    inet6 ::1/128 scope host\n       valid_lft forever preferred_lft forever\n6: eth0@if7: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc noqueue state UP group default\n    link/ether 02:42:ac:11:00:02 brd ff:ff:ff:ff:ff:ff link-netnsid 0\n    inet 172.17.0.2/16 brd 172.17.255.255 scope global eth0\n       valid_lft forever preferred_lft forever\n</code></pre> <p>ip: command not found</p> <p>Install the package <code>iproute2</code> that provides a collection of utilities for networking and traffic control. <pre><code>   apt update &amp;&amp; apt install -y iproute2\n</code></pre></p> <p>As we can see, we have the <code>lo</code> loopback interface and the <code>eth0@if7</code> network interface with an IP address of 172.17.0.2, just like any other host. </p> <p>We can also check its running processes:</p> <pre><code>root@0e539c9ccee4:/# ps aux\nUSER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot           1  0.0  0.0   4588  3968 pts/0    Ss   11:04   0:00 bash\nroot         334  0.0  0.1   7888  4224 pts/0    R+   11:08   0:00 ps aux\n</code></pre> <p>Note that the process <code>bash</code> has PID 1. </p> <p>Now type <code>exit</code> or the <code>CTRL-d</code> key sequence...you'll return to the command prompt of your Ubuntu host. So what's happened to our container?  The container only runs for as long as the command we specified, <code>/bin/bash</code>, is running. Once we exited the container, that command ended, and the container was stopped.</p> <p>So the container still exists but it's stopped: <pre><code>docker container ps -a\nCONTAINER ID   IMAGE         COMMAND    CREATED          STATUS                      PORTS     NAMES\n0e539c9ccee4   ubuntu        \"bash\"     5 minutes ago    Exited (0) 15 seconds ago             frosty_satoshi\na621c49ed3d6   hello-world   \"/hello\"   15 minutes ago   Exited (0) 15 minutes ago             bold_galileo\n</code></pre></p>"},{"location":"container/manipulation/#starting-a-stopped-container","title":"Starting a stopped container","text":"<p>We can start again our stopped container with <code>docker container start &lt;container-id or container-name&gt;</code>:</p> <p><pre><code>docker container start 0e539c9ccee4\n0e539c9ccee4\n</code></pre> Our container will restart with the same options we had specified when we launched it with the <code>docker run</code> command.</p>"},{"location":"container/manipulation/#attaching-to-a-container","title":"Attaching to a container","text":"<p>The <code>docker container attach</code> command allows you to attach your terminal to the running container. </p> <p>Tip</p> <p>The command that is executed when starting a container is specified using the ENTRYPOINT and/or CMD instruction in the Dockerfile. The <code>attach</code> command allows you to connect and interact with the container\u2019s main process which has <code>PID 1</code>. Remember that if you kill the main process the container will terminate.</p> <p>This is useful when you want to see what is written in the standard output in real-time, or to control the process interactively.</p> <p>So running the <code>attach</code> command on our Ubuntu container will bring us back to our bash prompt: <pre><code>docker attach 0e539c9ccee4\nroot@0e539c9ccee4:/#\n</code></pre></p> <p>You can detach from a container and leave it running using the <code>CTRL-p CTRL-q</code> key sequence.</p> <p>What happens if you type <code>exit</code>?</p>"},{"location":"container/manipulation/#getting-a-shell-to-a-container","title":"Getting a shell to a container","text":"<p>The <code>docker exec</code> command allows you to run commands inside a running container. The command can be run in background using the option <code>-d</code> or interactively using the option <code>-i</code>.</p> <p>Try the following command on your Ubuntu container:</p> <p><pre><code>docker exec -it 0e539c9ccee4 bash\nroot@0e539c9ccee4:/#\n</code></pre> Let's look at the processes inside the container: <pre><code>root@0e539c9ccee4:/# ps aux\nUSER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND\nroot           1  0.0  0.0   4588  3712 pts/0    Ss+  13:56   0:00 bash\nroot           9  0.1  0.0   4588  3968 pts/1    Ss   13:57   0:00 bash\nroot          17  0.0  0.1   7888  4096 pts/1    R+   13:57   0:00 ps aux\n</code></pre> We can see that the <code>exec</code> command started a new shell session. </p> <p>Tip</p> <p>Usually the <code>exec</code> command is used to launch <code>bash</code> within the container and work with that.  The <code>attach</code> command primarily is used if you quickly want to see the output of the main process (<code>PID 1</code>) directly and/or want to kill it.</p>"},{"location":"data/volume_plugin/","title":"Volume plugin","text":"<p>Docker Engine volume plugins enable Engine deployments to be integrated with external storage systems such as NFS, Ceph, Openstack Cinder, Amazon EBS, and enable data volumes to persist beyond the lifetime of a single Docker host.</p> <p>This section will show an example using the Netshare docker volume plugin to mount NFS shares inside our container.</p> <p>Note</p> <p>Netshare is a Docker volume plugin for NFS 3/4, EFS and CIFS/SMB. We will show its usage with NFS as an example. However consider that you can attach NFS volumes to docker containers using the <code>local</code> driver as well since docker provides natively the support for NFS. For example: <pre><code># docker volume create --driver local --opt type=nfs --opt o=addr=&lt;nfs server ip&gt;,rw --opt device=:&lt;export nfs path&gt; &lt;volume name&gt;\n</code></pre></p> <p>The plugin has been installed following the instructions provided in the docs.</p> <p>The NFS server has been installed on the machine with IP <code>192.168.28.53</code> and configured to export the path <code>/mnt/nfs_share/nginx</code>:</p> <pre><code>Export list for 192.168.28.53:\n/mnt/nfs_share/nginx   192.168.28.151\n</code></pre> <p>You can check that the docker plugin service is up and running on the docker host:</p> <pre><code>sudo systemctl status docker-volume-netshare\n</code></pre> <pre><code>\u25cf docker-volume-netshare.service - LSB: Init for docker-volume-netshare\n     Loaded: loaded (/etc/init.d/docker-volume-netshare; generated)\n     Active: active (running) since Sun 2021-06-13 13:23:58 UTC; 1h 6min ago\n       Docs: man:systemd-sysv-generator(8)\n    Process: 716471 ExecStart=/etc/init.d/docker-volume-netshare start (code=exited, status=0/SUCCESS)\n      Tasks: 5 (limit: 4683)\n     Memory: 6.3M\n     CGroup: /system.slice/docker-volume-netshare.service\n             \u2514\u2500716480 /usr/bin/docker-volume-netshare nfs\n\nJun 13 13:23:58 tutorvm-1 systemd[1]: Starting LSB: Init for docker-volume-netshare...\nJun 13 13:23:58 tutorvm-1 docker-volume-netshare[716471]:  * Starting Docker-Volume-Netshare: docker-volume-netshare\nJun 13 13:23:58 tutorvm-1 docker-volume-netshare[716471]:    ...done.\nJun 13 13:23:58 tutorvm-1 systemd[1]: Started LSB: Init for docker-volume-netshare.\n</code></pre> <p>Launch the <code>nginx</code> container with an NFS docker volume:</p> <pre><code>docker run -d -p 8081:80 --name nginx_nfs --volume-driver=nfs -v 192.168.28.53/mnt/nfs_share/nginx:/usr/share/nginx/html nginx\n</code></pre> <p>Check the volume list:</p> <pre><code>docker volume ls\nDRIVER    VOLUME NAME\nnfs       192.168.28.53/mnt/nfs_share/nginx\n</code></pre> <p>Inspect the volume:</p> <pre><code>docker inspect 192.168.28.53/mnt/nfs_share/nginx\n[\n    {\n        \"CreatedAt\": \"0001-01-01T00:00:00Z\",\n        \"Driver\": \"nfs\",\n        \"Labels\": null,\n        \"Mountpoint\": \"/var/lib/docker-volumes/netshare/nfs/192.168.28.53/mnt/nfs_share/nginx\",\n        \"Name\": \"192.168.28.53/mnt/nfs_share/nginx\",\n        \"Options\": null,\n        \"Scope\": \"local\"\n    }\n]\n</code></pre> <p>The plugin has automatically mounted the NFS volume on your docker host...look at the mounts:</p> <pre><code>sudo mount | grep nginx\n192.168.28.53:/mnt/nfs_share/nginx on /var/lib/docker-volumes/netshare/nfs/192.168.28.53/mnt/nfs_share/nginx type nfs4 (rw,relatime,vers=4.2,rsize=524288,wsize=524288,namlen=255,hard,proto=tcp,timeo=600,retrans=2,sec=sys,clientaddr=192.168.28.151,local_lock=none,addr=192.168.28.53)\n</code></pre> <p>Now connect to the deployed service (<code>nginx</code>) on port <code>8081</code>:</p> <p></p>"},{"location":"data/volume_summary/","title":"Summary","text":""},{"location":"data/volumes/","title":"Docker volumes and bind-mounts","text":"<p>Whenever a running container wants to write data, it actually put that data into the writable layer through a storage driver.</p> <p>We will now do some tasks using volumes. </p> <p>Let's create a volume:</p> CommandOutput <pre><code>docker volume create volume1\n</code></pre> <pre><code>volume1\n</code></pre> <p>and check that the volume has been created:</p> CommandOutput <pre><code>docker volume ls\n</code></pre> <pre><code>DRIVER    VOLUME NAME\nlocal     volume1\n</code></pre> <p>Let's do the same with a second volume:</p> CommandOutput <pre><code>docker volume create volume2\n</code></pre> <pre><code>volume2\n</code></pre> <p>and check:</p> CommandOutput <pre><code>docker volume ls\n</code></pre> <pre><code>DRIVER    VOLUME NAME\nlocal     volume1\nlocal     volume2\n</code></pre> <p>Let's now remove the second volume we've created:</p> CommandOutput <pre><code>docker volume rm volume2\n</code></pre> <pre><code>volume2\n</code></pre> <p>and check that it has actually been removed</p> CommandOutput <pre><code>docker volume ls\n</code></pre> <pre><code>DRIVER    VOLUME NAME\nlocal     volume1\n</code></pre> <p>Now let's dive into real-life (or quasi-real-life) usage of Docker volumes.</p> <p>Let's use our <code>nginx2</code> container created previously.</p> <p>Tip</p> <p>If you don't have this container running you can recreate it with the following command: <code>docker container run -d -p 80:80 --name nginx2 nginx</code></p> <p>Let\u2019s use the <code>docker exec</code> command to edit the welcome page and load it.</p> <p><pre><code>docker container exec -it nginx2 bash\n</code></pre> This wil open a bash shell and now you should now be inside your container. Run the following command to change the welcome page:</p> <pre><code>echo \"I changed the content of this file inside the running container...\" &gt; /usr/share/nginx/html/index.html\n</code></pre> <p>You will be able to see these changes connecting to the port 80 of your host:</p> <p></p> <p>Let\u2019s restart the container: <pre><code>docker container restart nginx2\n</code></pre></p> <p>What happens? We can still see in the browser the changes that we made. </p> <p>Now... what if we stop this container and start another one and load the page?</p> <pre><code>docker container run -d -p 8080:80 --name nginx3 nginx\n</code></pre> <p>Warning</p> <p>For this second container you need to specify a different host port, otherwise there will be a conflict and your container will not be started:</p> <p><code>driver failed programming external connectivity on endpoint nginx3 (96fad8e096e1a124147049765f0d734e2a034712fb253711450c62a7158b1f21): Bind for 0.0.0.0:80 failed: port is already allocated.</code></p> <p>Connect to port 8080 of your host, you will see the default welcome page: there is no way that we could access the file that we have changed in another container.</p> <p></p>"},{"location":"data/volumes/#using-docker-volumes","title":"Using docker volumes","text":"<p>Let's now create a docker volume to be used with our nginx container:</p> <pre><code>docker volume create myvol\n</code></pre> <p>We can see the location of volumes in the docker area of the host file system with the inspect command:</p> <pre><code>docker volume inspect myvol\n</code></pre> <p>whose output contains the following information: <pre><code>[\n    {\n        \"CreatedAt\": \"2021-06-07T10:53:26Z\",\n        \"Driver\": \"local\",\n        \"Labels\": {},\n        \"Mountpoint\": \"/var/lib/docker/volumes/myvol/_data\",\n        \"Name\": \"myvol\",\n        \"Options\": {},\n        \"Scope\": \"local\"\n    }\n]\n</code></pre></p> <p>Let's re-create our <code>nginx</code> container with the following command that mounts the volume <code>myvol</code> in <code>/usr/share/nginx/html</code>:</p> <p>Remove the old container (please note that the <code>-f</code> or <code>--force</code> flag is needed to delete a running container; otherwise, we should <code>docker container stop nginx3</code> first, then <code>docker container rm nginx3</code>): <pre><code>docker container rm -f nginx3\n</code></pre></p> <p>Recreate it with the volume mounted, using the <code>--mount</code> directive as in the following: <pre><code>docker container run -d -p 8080:80 --name nginx3 --mount type=volume,source=myvol,destination=/usr/share/nginx/html nginx\n</code></pre></p> <p>Note</p> <ul> <li>if we hadn\u2019t create the volume earlier, docker would have created it for us with the name given in source field of <code>--mount</code> parameter</li> <li>remember that volumes are not deleted when we erase the container which they are attached to</li> <li>if the container has got in <code>target</code> directory any files, this files will be copied into the volume</li> </ul> <p>Now let's enter the container and modify the welcome page (the <code>index.html</code> file served by nginx by default, located at <code>/usr/share/nginx/html/index.html</code> inside the container):</p> <pre><code>docker exec -it nginx3 bash\n</code></pre> <p>Once inside the container, run the following command:</p> <pre><code>echo \"I've changed the content of this file in the docker volume\" &gt; /usr/share/nginx/html/index.html\n</code></pre> <p></p> <p>Let' stop and remove this container::</p> <p><pre><code>docker rm -f nginx3\n</code></pre> and create a new one with the same command: <pre><code>docker container run -d -p 8080:80 --name nginx3 --mount type=volume,source=myvol,destination=/usr/share/nginx/html nginx\n</code></pre></p> <p>If we load the page again we will still see the html file that we edited in the volume.</p> <p>Now let's create another container sharing the same volume (we will now use port 8081, in order not to clash with the previous container):  <pre><code>docker container run -d -p 8081:80 --name nginx3-2 --mount type=volume,source=myvol,destination=/usr/share/nginx/html nginx\n</code></pre> then check that we see the same content: <pre><code>curl 192.168.28.151:8081\n</code></pre></p>"},{"location":"data/volumes/#using-bind-mounts","title":"Using bind mounts","text":"<p>Now we will create a container running nginx using a bind mount (with the <code>type=bind</code> directive) for the main served directory instead of a volume. </p> <p>Note</p> <ul> <li>if we didn\u2019t create a directory on docker host earlier docker will not create it for us with <code>--mount</code> parameter, auto-creating is available only in older <code>--volume</code></li> <li>bind mounts by default will not be deleted while removing the container</li> <li>if the container has got in <code>target</code> directory any files, this files will NOT be copied into bind mount directory, bind directory will cover any files in a target container directory</li> </ul> <p>Try the following command:</p> <pre><code>docker container run -d -p 8088:80 --name nginx4 --mount type=bind,source=/tmp/nginx,destination=/usr/share/nginx/html nginx\n</code></pre> <p>You will get an error since the path <code>/tmp/nginx</code> does not exist on the host: <pre><code>docker: Error response from daemon: invalid mount config for type \"bind\": bind source path does not exist: /tmp/nginx.\nSee 'docker run --help'.\n</code></pre></p> <p>Let's create the directory on the host:</p> <pre><code>mkdir /tmp/nginx\n</code></pre> <p>Now re-run the command for creating the container with the <code>/usr/share/nginx/html</code> directory mapped to the local (on the host) <code>/tmp/nginx</code>:</p> <pre><code>docker container run -d -p 8088:80 --name nginx4 --mount type=bind,source=/tmp/nginx,destination=/usr/share/nginx/html nginx\n</code></pre> <p>If you inspect the container:</p> <pre><code>docker container inspect nginx4\n</code></pre> <p>you will see the bind-mount: <pre><code>...\n            \"Mounts\": [\n                {\n                    \"Type\": \"bind\",\n                    \"Source\": \"/tmp/nginx\",\n                    \"Target\": \"/usr/share/nginx/html\"\n                }\n            ],\n...\n</code></pre></p> <p>Connect to port <code>8088</code> on the host IP to see the result:</p> <p></p> <p>As you can see we get an error message from nginx as the bind-mount has overwritten the content of <code>/usr/share/nginx/html</code> (remember that the behaviour with docker volumes is different, any file inside the container is copied in the volume)</p> <p>Let's now create the <code>index.html</code> file in the host path <code>/tmp/nginx</code>:</p> <pre><code>echo \"I've changed the content of this file on the host\" &gt; /tmp/nginx/index.html\n</code></pre> <p>Then reload the page in the browser:</p> <p> </p> <p>Question</p> <p>As done before, try to remove the container and recreate it with the same bind-mount...what happens?</p>"},{"location":"data/volumes/#lab-challenge","title":"Lab challenge","text":"<p>Goal: create a service based on two containers: </p> <ol> <li>WordPress </li> <li>MariaDB </li> </ol> <p>and then use your web browser to access wordpress on port 80.</p> <p>Tip</p> <ul> <li>Create a volume <code>db_data</code> to provide persistent storage for the DBMS</li> <li>Launch MariaDB (image name: <code>mariadb:10.6.4-focal</code>) with container name <code>db</code>, using the previously created volume, and pass environment variables to the container to configure it</li> <li>Inspect the MariaDB container finding its private IP</li> <li>Launch WordPress (image name: <code>wordpress:latest</code>) with container name <code>wordpress</code>, and pass environment variables to the container to configure it (using as DB host the IP of the MariaDB container).</li> </ul>"},{"location":"gui/portainer/","title":"Portainer","text":"<p>Portainer is a lightweight management UI which allows you to easily manage your different Docker environments (Docker hosts or Swarm clusters). Portainer is meant to be as simple to deploy as it is to use. It consists of a single container that can run on any Docker engine.</p>"},{"location":"gui/portainer/#installation","title":"Installation","text":"<pre><code>docker volume create portainer_data\n</code></pre> <pre><code>docker run -d -p 9000:9000 --name=portainer --restart=always -v /var/run/docker.sock:/var/run/docker.sock -v portainer_data:/data portainer/portainer-ce\n</code></pre>"},{"location":"gui/portainer/#usage","title":"Usage","text":"<p>The UI will be exposed on port <code>9000</code> and you will be asked to create the initial administrator setting a password:</p> <p></p> <p>Then choose to manage the local Docker environment clicking on <code>Get Started</code>:</p> <p></p> <p>If everything works as expected, you will then be shown the Portainer home page. Click on the <code>local</code> environment:</p> <p></p> <p>In the menu, clicking on <code>Dashboard</code> will open a summary view of your docker engine:</p> <p></p> <p>Clicking on <code>Containers</code> will allow you to manage containers:</p> <p></p> <p>Then click on one running container to get the container status and menu from which you can see the log and statistics: </p> <p></p> <p></p> <p>Exercise</p> <p>Now go back to the <code>Containers</code> page and try to add a new container. </p>"},{"location":"image/automation/","title":"How to use Gitlab CI/CD to build your image automatically","text":"<p>In this section you'll learn how to leverage CI/CD pipilines in INFN baltig (or any other gitlab instance) in order to automatically build your images and to push them to the gitlab container registry.  </p>"},{"location":"image/automation/#requirements","title":"Requirements","text":"<ul> <li>baltig.infn.it account and access</li> <li>gitlab CLI:     <pre><code>wget https://gitlab.com/gitlab-org/cli/-/releases/v1.46.0/downloads/glab_1.46.0_Linux_x86_64.deb\nsudo dpkg -i glab_1.46.0_Linux_x86_64.deb\n</code></pre></li> <li>a baltig token with 'api' and 'write_repository' scopes (see below)</li> <li>having followed the previous tutorial</li> </ul>"},{"location":"image/automation/#create-a-git-repository-with-your-app","title":"Create a git repository with your app","text":"<p>Let's initialize a git repository in our <code>flask</code> dir:</p> <pre><code>cd flask\ngit init\ngit switch -c main\ngit config --global user.name \"Diego Ciangottini\"\ngit config --global user.email \"diego.ciangottini@pg.infn.it\"\n</code></pre> <p>Login in baltig via:</p> <pre><code>$ glab auth login\n? What GitLab instance do you want to log into? GitLab Self-hosted Instance\n? GitLab hostname: baltig.infn.it\n? API hostname: baltig.infn.it\n- Logging into baltig.infn.it\n? How would you like to login? Token\n\nTip: you can generate a Personal Access Token here https://baltig.infn.it/-/profile/personal_access_tokens\nThe minimum required scopes are 'api' and 'write_repository'.\n? Paste your authentication token: ********************\n? Choose default git protocol HTTPS\n? Authenticate Git with your GitLab credentials? Yes\n? Choose host API protocol HTTPS\n- glab config set -h baltig.infn.it git_protocol https\n\u2713 Configured git protocol\n- glab config set -h baltig.infn.it api_protocol https\n\u2713 Configured API protocol\n\u2713 Logged in as project_4873_bot\n</code></pre>"},{"location":"image/automation/#create-a-pipeline-to-automatically-build-your-image","title":"Create a pipeline to automatically build your image","text":"<p>Create a file <code>.gitlab-ci.yml</code> with your workflow description:</p> <pre><code>build_base_image:\n  image: docker:latest\n  stage: build\n  services:\n    - docker:dind\n  before_script:\n    - echo 'docker login -u ${CI_REGISTRY_USER} -p ${CI_REGISTRY_PASSWORD} baltig.infn.it:4567'\n    - docker login -u ${CI_REGISTRY_USER} -p ${CI_REGISTRY_PASSWORD} baltig.infn.it:4567\n  # Default branch leaves tag empty (= latest tag)\n  # All other branches are tagged with the escaped branch name (commit ref slug)\n  script:\n    - |\n      if [[ \"$CI_COMMIT_BRANCH\" == \"$CI_DEFAULT_BRANCH\" ]]; then\n        tag=\":latest\"\n        echo \"Running on default branch '$CI_DEFAULT_BRANCH': tag = 'latest'\"\n      else\n        tag=\":$CI_COMMIT_REF_SLUG\"\n        echo \"Running on branch '$CI_COMMIT_BRANCH': tag = $tag\"\n      fi\n      docker build -t \"$CI_REGISTRY_IMAGE${tag}\" .\n      docker push \"$CI_REGISTRY_IMAGE${tag}\"\n</code></pre> <p>And then commit everything into gitlab that you already created in previous tutorials:</p> <pre><code>git remote add origin https://baltig.infn.it/ciangottini/tutorial-ci.git\ngit add .\ngit commit -m \"Initial commit\"\ngit push -u origin main\n</code></pre> <p>Warning</p> <p>Remember to replace <code>ciangottini</code> with your baltig username!!</p>"},{"location":"image/automation/#monitor-the-building-process","title":"Monitor the building process","text":"<p>Pipeline monitoring page is available at your repo site like <code>https://baltig.infn.it/ciangottini/tutorial-ci/-/pipelines</code></p> <p>Or via CLI:</p> <pre><code>$ glab ci list\nShowing 3 pipelines on ciangottini/tutorial-ci (Page 1)\n\n(running) \u2022 #82282  main  (less than a minute ago)\n(failed) \u2022 #82281   main  (about 4 minutes ago)   \n(failed) \u2022 #82280   main  (about 7 minutes ago)\n</code></pre> <p>and then you can get details via <code>glab ci view #82281</code>. Or you than live tracing the progress log via <code>glab ci trace #82285</code></p> <p>Once completed you should be able to see the docker image stored on gitlab registry at something like <code>https://baltig.infn.it/ciangottini/tutorial-ci/container_registry</code></p> <p>The container is now ready to be pulled from the registry via: <code>docker pull baltig.infn.it:4567/ciangottini/tutorial-ci</code></p>"},{"location":"image/automation/#exercises","title":"Exercises","text":"<ul> <li> <p>Create a pipeline to periodically build your latest tag</p> </li> <li> <p>Push image to dockerHUB instead</p> </li> </ul>"},{"location":"image/automation/ghaction/","title":"How to use Github actions to build your image automatically","text":""},{"location":"image/automation/ghaction/#create-a-new-repository-on-github","title":"Create a New Repository on GitHub","text":"<ol> <li>Go to GitHub and log in to your account.</li> <li>Click the <code>+</code> icon in the top right corner and select <code>New repository</code>.</li> <li>Fill out the repository name and description, then click <code>Create repository</code>.</li> </ol>"},{"location":"image/automation/ghaction/#add-github-as-a-remote","title":"Add GitHub as a Remote","text":"<p>Add your newly created GitHub repository as a remote:</p> <pre><code>git remote add github https://github.com/username/repository-name.git\n</code></pre>"},{"location":"image/automation/ghaction/#create-a-github-personal-access-token","title":"Create a GitHub Personal Access Token:","text":"<ol> <li>Go to GitHub Personal Access Tokens.</li> <li>Click <code>Generate new token</code>.</li> <li>Add a note, select the <code>repo</code> scope for full control of private repositories, and any other necessary scopes.</li> <li>Click <code>Generate token</code> and copy the token. This will be used as your GitHub authentication token.</li> </ol>"},{"location":"image/automation/ghaction/#push-your-repository-to-github","title":"Push Your Repository to GitHub","text":"<p>Push your repository\u2019s branches to GitHub:</p> <pre><code>git push github --all\n</code></pre>"},{"location":"image/automation/ghaction/#create-a-github-action-to-build-and-push-docker-images","title":"Create a GitHub Action to Build and Push Docker Images","text":"<p>In your GitHub repository, create the necessary directory for GitHub Actions workflows:</p> <pre><code>mkdir -p .github/workflows\n</code></pre> <p>Create a new file in the <code>.github/workflows</code> directory, e.g., <code>build-and-push.yml</code>:</p> <pre><code>name: Build and push docker image to Docker Hub\n\non:\n  push:\n    branches: [ main ]\n  pull_request:\n    branches: [ main ]\n\n  workflow_dispatch:\n\njobs:\n  docker:\n    runs-on: ubuntu-latest\n    steps:\n      -\n        name: Checkout\n        uses: actions/checkout@v4\n      -\n        name: Set up Docker Buildx\n        uses: docker/setup-buildx-action@v2\n      -\n        name: Login to DockerHub\n        uses: docker/login-action@v2 \n        with:\n          username: ${{ secrets.DOCKERHUB_USERNAME }}\n          password: ${{ secrets.DOCKERHUB_TOKEN }}\n      - \n        name: Docker meta\n        id: docker_meta\n        uses: crazy-max/ghaction-docker-meta@v2\n        with:\n          images: ${{ secrets.DOCKERHUB_USERNAME }}/slat\n          tags: |\n            type=sha\n            type=semver,pattern={{raw}}\n            type=ref,event=branch\n      - \n        name: Build &amp; Push image\n        uses: docker/build-push-action@v2\n        with:\n          context: .\n          file: Dockerfile\n          push: true\n          tags: ${{ steps.docker_meta.outputs.tags }}\n          labels: ${{ steps.docker_meta.outputs.labels }}\n</code></pre>"},{"location":"image/automation/ghaction/#add-secrets-to-your-github-repository","title":"Add Secrets to Your GitHub Repository:","text":"<ul> <li>Go to your GitHub repository and navigate to <code>Settings</code>.</li> <li>Select <code>Secrets and variables</code> \u2192 <code>Actions</code>.</li> <li>Click <code>New repository secret</code> and add the following secrets:</li> <li><code>DOCKERHUB_USERNAME</code>: Your Docker Hub username.</li> <li><code>DOCKERHUB_PASSWORD</code>: Your Docker Hub password or access token.</li> </ul>"},{"location":"image/automation/ghaction/#commit-and-push-the-workflow-file","title":"Commit and Push the Workflow File","text":"<p>Add, commit, and push the workflow file to your GitHub repository:</p> <pre><code>git add .github/workflows/build-and-push.yml\ngit commit -m \"Add GitHub Actions workflow for Docker build and push\"\ngit push\n</code></pre>"},{"location":"image/automation/runner/","title":"Use your own runner from a dedicated VM","text":"<p>In this section we will add a dedicated GitLab runner to the CI/CD infrastructure. The runner will execute inside a docker container.</p> <ol> <li>Create the docker volume:    <pre><code>docker volume create gitlab-runner-config\n</code></pre></li> <li> <p>Start the GitLab runner container using the volume we have just created:    <pre><code>docker run -d --name gitlab-runner --restart always \\\n-v /var/run/docker.sock:/var/run/docker.sock \\\n-v gitlab-runner-config:/etc/gitlab-runner \\\ngitlab/gitlab-runner:latest \n</code></pre>    Check your container is running:    <pre><code>docker ps\nCONTAINER ID   IMAGE                         COMMAND                  CREATED         STATUS         PORTS     NAMES\n94f0a1bdc4de   gitlab/gitlab-runner:latest   \"/usr/bin/dumb-init \u2026\"   6 minutes ago   Up 5 minutes             gitlab-runner\n</code></pre></p> </li> <li> <p>Register the runner</p> <ol> <li>Obtain a token:       Visit your project web page (at <code>https://baltig.infn.it/USERNAME/tutorial-ci</code>) and go to Settings &gt; CI/CD and expand the Runners section:              Click \"New project runner\" under the section Project runners:              Select the option \"Run untagged jobs\" as shown in the next figure:              Copy the token displayed in step 1:       </li> <li>Launch the following command replacing the <code>***********</code> with the token you have just copied:       <pre><code>docker exec -it gitlab-runner gitlab-runner register -n --url https://baltig.infn.it \\\n--token *********** --description \"My Docker Runner\" \\\n--executor docker --docker-image \"docker:latest\" \\\n--docker-volumes /var/run/docker.sock:/var/run/docker.sock\n</code></pre>       If the registration is successful you will get a similar message:       <pre><code>Runtime platform                                    arch=amd64 os=linux pid=16 revision=8ec04662 version=16.3.0\nRunning in system-mode.\n\nVerifying runner... is valid                        runner=5sYMm3yvH\nRunner registered successfully. Feel free to start it, but if it's running already the config should be automatically reloaded!\n\nConfiguration (with the authentication token) was saved in \"/etc/gitlab-runner/config.toml\"\n</code></pre>       You will see the message about the successful registration also in the web page:              and your runner will appear under the specific runners of the project:       </li> </ol> </li> </ol> <p>Now you can disable the shared runners and use your newly created one: </p> <p>Let's trigger our pipeline. You can commit a change in your repository or trigger it manually from CI/CD &gt; Pipelines: </p> <p>You can also look at the runner logs using the command <code>docker logs gitlab-runner</code>:</p> <pre><code>docker logs -f gitlab-runner\nRuntime platform                                    arch=amd64 os=linux pid=7 revision=8ec04662 version=16.3.0\nStarting multi-runner from /etc/gitlab-runner/config.toml...  builds=0 max_builds=0\nRunning in system-mode.\n\nCreated missing unique system ID                    system_id=r_P8aAkaba4WdQ\nConfiguration loaded                                builds=0 max_builds=1\nlisten_address not defined, metrics &amp; debug endpoints disabled  builds=0 max_builds=1\n[session_server].listen_address not defined, session endpoints disabled  builds=0 max_builds=1\nInitializing executor providers                     builds=0 max_builds=1\nChecking for jobs... received                       job=399659 repo_url=https://baltig.infn.it/antonacci/tutorial-ci.git runner=N83zBFyfs\nAdded job to processing list                        builds=1 job=399659 max_builds=1 project=4884 repo_url=https://baltig.infn.it/antonacci/tutorial-ci.git\nAppending trace to coordinator...ok                 code=202 job=399659 job-log=0-281 job-status=running runner=N83zBFyfs sent-log=0-280 status=202 Accepted update-interval=3s\nAppending trace to coordinator...ok                 code=202 job=399659 job-log=0-369 job-status=running runner=N83zBFyfs sent-log=281-368 status=202 Accepted update-interval=3s\nAppending trace to coordinator...ok                 code=202 job=399659 job-log=0-580 job-status=running runner=N83zBFyfs sent-log=369-579 status=202 Accepted update-interval=3s\nAppending trace to coordinator...ok                 code=202 job=399659 job-log=0-655 job-status=running runner=N83zBFyfs sent-log=580-654 status=202 Accepted update-interval=3s\nAppending trace to coordinator...ok                 code=202 job=399659 job-log=0-2246 job-status=running runner=N83zBFyfs sent-log=655-2245 status=202 Accepted update-interval=3s\nAppending trace to coordinator...ok                 code=202 job=399659 job-log=0-2590 job-status=running runner=N83zBFyfs sent-log=2246-2589 status=202 Accepted update-interval=3s\nAppending trace to coordinator...ok                 code=202 job=399659 job-log=0-2664 job-status=running runner=N83zBFyfs sent-log=2590-2663 status=202 Accepted update-interval=3s\nAppending trace to coordinator...ok                 code=202 job=399659 job-log=0-2803 job-status=running runner=N83zBFyfs sent-log=2664-2802 status=202 Accepted update-interval=3s\nAppending trace to coordinator...ok                 code=202 job=399659 job-log=0-3081 job-status=running runner=N83zBFyfs sent-log=2803-3080 status=202 Accepted update-interval=3s\nAppending trace to coordinator...ok                 code=202 job=399659 job-log=0-3443 job-status=running runner=N83zBFyfs sent-log=3081-3442 status=202 Accepted update-interval=3s\nAppending trace to coordinator...ok                 code=202 job=399659 job-log=0-4295 job-status=running runner=N83zBFyfs sent-log=3443-4294 status=202 Accepted update-interval=3s\nAppending trace to coordinator...ok                 code=202 job=399659 job-log=0-4333 job-status=running runner=N83zBFyfs sent-log=4295-4332 status=202 Accepted update-interval=3s\nAppending trace to coordinator...ok                 code=202 job=399659 job-log=0-4413 job-status=running runner=N83zBFyfs sent-log=4333-4412 status=202 Accepted update-interval=3s\nAppending trace to coordinator...ok                 code=202 job=399659 job-log=0-4500 job-status=running runner=N83zBFyfs sent-log=4413-4499 status=202 Accepted update-interval=3s\nAppending trace to coordinator...ok                 code=202 job=399659 job-log=0-4724 job-status=running runner=N83zBFyfs sent-log=4500-4723 status=202 Accepted update-interval=3s\nAppending trace to coordinator...ok                 code=202 job=399659 job-log=0-5595 job-status=running runner=N83zBFyfs sent-log=4724-5594 status=202 Accepted update-interval=3s\nAppending trace to coordinator...ok                 code=202 job=399659 job-log=0-6264 job-status=running runner=N83zBFyfs sent-log=5595-6263 status=202 Accepted update-interval=3s\nAppending trace to coordinator...ok                 code=202 job=399659 job-log=0-6334 job-status=running runner=N83zBFyfs sent-log=6264-6333 status=202 Accepted update-interval=3s\nAppending trace to coordinator...ok                 code=202 job=399659 job-log=0-6439 job-status=running runner=N83zBFyfs sent-log=6334-6438 status=202 Accepted update-interval=3s\nAppending trace to coordinator...ok                 code=202 job=399659 job-log=0-6579 job-status=running runner=N83zBFyfs sent-log=6439-6578 status=202 Accepted update-interval=3s\nAppending trace to coordinator...ok                 code=202 job=399659 job-log=0-6818 job-status=running runner=N83zBFyfs sent-log=6579-6817 status=202 Accepted update-interval=3s\nAppending trace to coordinator...ok                 code=202 job=399659 job-log=0-6985 job-status=running runner=N83zBFyfs sent-log=6818-6984 status=202 Accepted update-interval=3s\nJob succeeded                                       duration_s=144.960209393 job=399659 project=4884 runner=N83zBFyfs\nAppending trace to coordinator...ok                 code=202 job=399659 job-log=0-7061 job-status=running runner=N83zBFyfs sent-log=6985-7060 status=202 Accepted update-interval=3s\nUpdating job...                                     bytesize=7061 checksum=crc32:77dc11c0 job=399659 runner=N83zBFyfs\nSubmitting job to coordinator...ok                  bytesize=7061 checksum=crc32:77dc11c0 code=200 job=399659 job-status= runner=N83zBFyfs update-interval=0s\nRemoved job from processing list                    builds=0 job=399659 max_builds=1 project=4884 repo_url=https://baltig.infn.it/antonacci/tutorial-ci.git\n</code></pre>"},{"location":"image/cacheimages/cache-dangling/","title":"... or what are those nasty <none> tags","text":"<p>Let's do a quick check on our docker system: </p> <pre><code>docker images\n\nREPOSITORY                    TAG       IMAGE ID       CREATED         SIZE\ntest                          latest    259e2e6b1ac1   7 minutes ago   101MB\n&lt;none&gt;                        &lt;none&gt;    589c6427b137   7 minutes ago   101MB\nubuntu                        18.04     81bcf752ac3d   3 weeks ago     63.1MB\ngcr.io/k8s-minikube/kicbase   v0.0.22   bcd131522525   5 weeks ago     1.09GB\n</code></pre> <p>we should wonder what are the images with a <code>&lt;none&gt;</code> tag, you can see when you list all the images present on your system</p> <p>Tip</p> <p>Spolinig: these are dagnling images</p> <p>One thing more: </p> <pre><code>docker images -a \n\nREPOSITORY                    TAG       IMAGE ID       CREATED         SIZE\ntest                          latest    259e2e6b1ac1   7 minutes ago   101MB\n&lt;none&gt;                        &lt;none&gt;    589c6427b137   7 minutes ago   101MB\n&lt;none&gt;                        &lt;none&gt;    e63fa5024b8d   7 minutes ago   101MB\n&lt;none&gt;                        &lt;none&gt;    24a0ae7fb9f2   7 minutes ago   101MB\n&lt;none&gt;                        &lt;none&gt;    333abd901bf3   7 minutes ago   99.7MB\nubuntu                        18.04     81bcf752ac3d   3 weeks ago     63.1MB\ngcr.io/k8s-minikube/kicbase   v0.0.22   bcd131522525   5 weeks ago     1.09GB\n</code></pre> <p>again: why there are these images with a <code>&lt;none&gt;</code> tag, you can see when you list all the images present on your system</p> <p>Tip</p> <p>Spolinig: these are intermediate cached images</p> <p>Let's clean-up all our docker environment and use our previusly developed Dockerfile to package the application</p> <pre><code>docker system prune\n</code></pre> <ul> <li>Be carefull! this wil clean-up a lot: <ul> <li>all stopped containers</li> <li>all networks not used by at least one container</li> <li>all dangling images</li> <li>all dangling build cache</li> </ul> </li> </ul> <p>there are other way to select what to remove see here [REF]</p> <p>Tip</p> <ul> <li><code>docker rmi $(docker images -a --filter=dangling=true -q)</code></li> <li><code>docker rm $(docker ps --filter=status=exited --filter=status=created -q)</code></li> </ul> <p>once we have cleaned our system we will get something like the following: </p> <pre><code> \n$ docker images\nREPOSITORY                    TAG       IMAGE ID       CREATED       SIZE\ngcr.io/k8s-minikube/kicbase   v0.0.22   bcd131522525   5 weeks ago   1.09GB\nubuntu                        latest    7e0aa2d69a15   7 weeks ago   72.7MB\n\n\n$ docker images  -a\nREPOSITORY                    TAG       IMAGE ID       CREATED       SIZE\ngcr.io/k8s-minikube/kicbase   v0.0.22   bcd131522525   5 weeks ago   1.09GB\nubuntu                        latest    7e0aa2d69a15   7 weeks ago   72.7MB\ntutor5@tutorvm-5:~/myimage$ \n</code></pre> <p>this is time now to build our application. So let's start again with our Dockerfile:</p> <pre><code>FROM ubuntu:18.04\nRUN apt-get update\nRUN apt-get install -y figlet\nENTRYPOINT [\"figlet\", \"-f\", \"script\"]\nCMD [\"pippo\"]\n</code></pre> <p>Now we can build it and we will get something like this: </p> <pre><code>\ndocker build -t testnone .\n\nSending build context to Docker daemon  2.048kB\nStep 1/5 : FROM ubuntu:18.04\n18.04: Pulling from library/ubuntu\n4bbfd2c87b75: Pull complete \nd2e110be24e1: Pull complete \n889a7173dcfe: Pull complete \nDigest: sha256:67b730ece0d34429b455c08124ffd444f021b81e06fa2d9cd0adaf0d0b875182\nStatus: Downloaded newer image for ubuntu:18.04\n ---&gt; 81bcf752ac3d\nStep 2/5 : RUN apt-get update\n ---&gt; Running in 80bb3a4b5a8c\n... ( remove output ) \nReading package lists...\nRemoving intermediate container 80bb3a4b5a8c\n ---&gt; e095319ffe18\nStep 3/5 : RUN apt-get install figlet\n ---&gt; Running in 30b20940a069\n.... ( remove output ) \nRemoving intermediate container 30b20940a069\n ---&gt; 9ad1cce70073\nStep 4/5 : ENTRYPOINT [\"figlet\", \"-f\", \"script\"]\n ---&gt; Running in 911a64ae9765\nRemoving intermediate container 911a64ae9765\n ---&gt; cca054892aec\nStep 5/5 : CMD [\"pippo\"]\n ---&gt; Running in 67d507ed70c0\nRemoving intermediate container 67d507ed70c0\n ---&gt; f0684153d22f\nSuccessfully built f0684153d22f\nSuccessfully tagged testnone:latest\n</code></pre> <p>and let's check again our system: </p> <pre><code>\ntutor5@tutorvm-5:~/myimage$ docker images\nREPOSITORY                    TAG       IMAGE ID       CREATED              SIZE\ntestnone                      latest    f0684153d22f   About a minute ago   101MB\nubuntu                        18.04     81bcf752ac3d   3 weeks ago          63.1MB\ngcr.io/k8s-minikube/kicbase   v0.0.22   bcd131522525   5 weeks ago          1.09GB\nubuntu                        latest    7e0aa2d69a15   7 weeks ago          72.7MB\n</code></pre> <p>alright but then if I check further: </p> <pre><code>\ntutor5@tutorvm-5:~/myimage$ docker images -a \nREPOSITORY                    TAG       IMAGE ID       CREATED              SIZE\ntestnone                      latest    f0684153d22f   About a minute ago   101MB\n&lt;none&gt;                        &lt;none&gt;    cca054892aec   About a minute ago   101MB\n&lt;none&gt;                        &lt;none&gt;    9ad1cce70073   About a minute ago   101MB\n&lt;none&gt;                        &lt;none&gt;    e095319ffe18   2 minutes ago        99.7MB\nubuntu                        18.04     81bcf752ac3d   3 weeks ago          63.1MB\ngcr.io/k8s-minikube/kicbase   v0.0.22   bcd131522525   5 weeks ago          1.09GB\nubuntu                        latest    7e0aa2d69a15   7 weeks ago          72.7MB\n</code></pre> <p>where those come from ?  Those are the intermediate images genereated while building our image:</p> <pre><code>\nRemoving intermediate container 80bb3a4b5a8c\n ---&gt; e095319ffe18\nStep 3/5 : RUN apt-get install figlet\n ---&gt; Running in 30b20940a069\n.... ( remove output )\nRemoving intermediate container 30b20940a069\n ---&gt; 9ad1cce70073\nStep 4/5 : ENTRYPOINT [\"figlet\", \"-f\", \"script\"]\n ---&gt; Running in 911a64ae9765\nRemoving intermediate container 911a64ae9765\n ---&gt; cca054892aec\n</code></pre> <ul> <li>a container is run</li> <li>changes corresponding to the instruction defined in the step are done inside of this container</li> <li>the container is committed into an image (that is an intermediate image) that will be used as the base image of the next step</li> </ul> <p>Now the last step.. let's change our build starting from the previous Dockerfile and changing it: </p> <pre><code>FROM ubuntu:18.04\nRUN apt-get update\nRUN apt-get install -y figlet\nENTRYPOINT [\"figlet\", \"-f\", \"script\"]\nCMD [\"ciccio\"]  &lt;----\n</code></pre> <p>build it as we did before: </p> <pre><code>\ndocker build -t testnone .\nSending build context to Docker daemon  2.048kB\nStep 1/5 : FROM ubuntu:18.04\n ---&gt; 81bcf752ac3d\nStep 2/5 : RUN apt-get update\n ---&gt; Using cache\n ---&gt; e095319ffe18\nStep 3/5 : RUN apt-get install figlet\n ---&gt; Using cache\n ---&gt; 9ad1cce70073\nStep 4/5 : ENTRYPOINT [\"figlet\", \"-f\", \"script\"]\n ---&gt; Using cache\n ---&gt; cca054892aec\nStep 5/5 : CMD [\"Ciccio\"]\n ---&gt; Running in 976759d6217c\nRemoving intermediate container 976759d6217c\n ---&gt; 3624cff02928\nSuccessfully built 3624cff02928\nSuccessfully tagged testnone:latest\n</code></pre> <p>and now check again your images.. </p> <pre><code>\ndocker images\n\nREPOSITORY                    TAG       IMAGE ID       CREATED          SIZE\ntestnone                      latest    3624cff02928   4 seconds ago    101MB\n&lt;none&gt;                        &lt;none&gt;    f0684153d22f   17 minutes ago   101MB\nubuntu                        18.04     81bcf752ac3d   3 weeks ago      63.1MB\ngcr.io/k8s-minikube/kicbase   v0.0.22   bcd131522525   5 weeks ago      1.09GB\nubuntu                        latest    7e0aa2d69a15   7 weeks ago      72.7MB\n</code></pre> <p>Now, this IMAGE ID f0684153d22f is not more linked to the image named <code>testnone</code>  cause the second build has set it on the newly created image (the one containing the changes we did in Dockerfile)</p> <p>The previous image, now considered as dangling, is not referenced anymore. We can remove it, but we probably first need to make sure we have not used the same tag in the second build by mistake (that happens :) )</p> <p>If needed, you can tag again the dandling image any other image ( we saw it previously ) </p> <p>Finally, in order to check ( and possibly remove ) the dangling images you can play with something like this: </p> <pre><code> docker images -a --filter=dangling=true \n</code></pre>"},{"location":"image/dockerfile/cmd-entrypoint/","title":"The CMD and ENTRYPOINT verbs","text":"<p><code>CMD</code> and <code>ENTRYPOINT</code> are the commands that allow us to set the default command to run in a container.</p>"},{"location":"image/dockerfile/cmd-entrypoint/#adding-cmd-to-our-dockerfile","title":"Adding CMD to our Dockerfile","text":"<p>As example: we want to se a nice hello message, and using a custom font in our docker container, for that reason we will execute:</p> <p><code>figlet -f script hello</code></p> <p>Tip</p> <ul> <li><code>-f script</code> tells figlet to use a fancy font.</li> <li><code>hello</code> is the message that we want it to display.</li> </ul> <p>Let's modify our Dockerfile to support this default: </p> <pre><code>FROM ubuntu\nRUN apt-get update\nRUN apt-get install -y figlet\nCMD figlet -f script hello\n</code></pre> <p>and let's build it again : </p> <pre><code>docker build -t myfiglet .\n</code></pre> <p>This time you will see the effect of the cache and the output is the following: </p> <pre><code>Sending build context to Docker daemon  2.048kB\nStep 1/4 : FROM ubuntu:18.04\n ---&gt; 81bcf752ac3d\nStep 2/4 : RUN apt-get update\n ---&gt; Using cache\n ---&gt; e2ed94338e24\nStep 3/4 : RUN apt-get install figlet\n ---&gt; Using cache\n ---&gt; d9c8c229f154\nStep 4/4 : CMD figlet -f script hello\n ---&gt; Running in a9f4bc819ea7\nRemoving intermediate container a9f4bc819ea7\n ---&gt; e14a6ebfbd5e\nSuccessfully built e14a6ebfbd5e\nSuccessfully tagged myfiglet:latest\n</code></pre> <p>Run it:</p> <pre><code>docker run -ti myfiglet \n</code></pre> <p>The output will looks like the following: </p> <pre><code> _          _   _       \n| |        | | | |      \n| |     _  | | | |  __  \n|/ \\   |/  |/  |/  /  \\_\n|   |_/|__/|__/|__/\\__/ \n</code></pre>"},{"location":"image/dockerfile/cmd-entrypoint/#overriding-cmd","title":"Overriding CMD","text":"<p>If we want to get a shell into our container (instead of running figlet), we just have to specify a different program to run. If we aspecify <code>bash</code>, it will replace the value of <code>CMD</code>.</p> <p>Try it:</p> <pre><code>docker run -it myfiglet bash\n</code></pre>"},{"location":"image/dockerfile/cmd-entrypoint/#using-entrypoint","title":"Using ENTRYPOINT","text":"<p>And what about if We want to be able to specify a different message on the command line, while retaining figlet and some default parameters? Example: we  would like to be able to do this:</p> <pre><code>docker run myfiglet Good Morning\n</code></pre> <p>We will use the <code>ENTRYPOINT</code> verb in Dockerfile</p> <pre><code>FROM ubuntu\nRUN apt-get update\nRUN apt-get install -y figlet\nENTRYPOINT [\"figlet\", \"-f\", \"script\"]\n</code></pre> <p>Tip</p> <ul> <li>ENTRYPOINT defines a base command (and its parameters) for the container.</li> <li>The command line arguments are appended to those parameters.</li> <li>Like CMD, ENTRYPOINT can appear anywhere, and replaces the previous value.</li> </ul> <p>When CMD or ENTRYPOINT use string syntax, they get wrapped in <code>sh -c</code> and it would run the following command in the figlet image: <pre><code>sh -c \"figlet -f script\" salut\n</code></pre> To avoid this wrapping, we can use JSON syntax.</p> <p>Let's build and test:</p> <p><pre><code>docker build -t myfiglet .\n</code></pre> and run:  <pre><code>docker run  myfiglet pippo\n\n      o                 \n   _       _    _   __  \n |/ \\_|  |/ \\_|/ \\_/  \\_\n |__/ |_/|__/ |__/ \\__/ \n/|      /|   /|         \n\\|      \\|   \\|         \n</code></pre></p> <p>If we want to run a shell in our container, We cannot just do <code>docker run myfiglet bash</code> because that would just tell figlet to display the word \"bash.\"</p> <p>We use the --entrypoint parameter:</p> <pre><code>$ docker run -it --entrypoint bash myfiglet\nroot@6027e44e2955:/#\n</code></pre>"},{"location":"image/dockerfile/cmd-entrypoint/#combine-cmd-and-entrypoint","title":"Combine CMD and ENTRYPOINT","text":"<p>What if we want to define a default message for our container?</p> <p>Then we will use ENTRYPOINT and CMD together.</p> <p>ENTRYPOINT will define the base command for our container.</p> <p>CMD will define the default parameter(s) for this command.</p> <p>They both have to use JSON syntax.</p> <p>ENTRYPOINT defines a base command (and its parameters) for the container.</p> <p>If we don't specify extra command-line arguments when starting the container, the value of CMD is appended.</p> <p>Otherwise, our extra command-line arguments are used instead of CMD.</p> <pre><code>FROM ubuntu:18.04\nRUN apt-get update\nRUN apt-get install -y figlet\nENTRYPOINT [\"figlet\", \"-f\", \"script\"]\nCMD [\"ciccio\"]\n</code></pre> <p>Tip</p> <p>Finally CMD and ENTRYPOINT recap - <code>docker run myimage</code> executes ENTRYPOINT + CMD - <code>docker run myimage args</code> executes ENTRYPOINT + args (overriding CMD) - <code>docker run --entrypoint prog myimage</code> executes prog (overriding both)</p>"},{"location":"image/dockerfile/copy/","title":"Copying files during the build","text":"<p>This section is about another Dockerfile keyword: COPY.</p> <p>During the previous sections we have installed things in our container images by downloading packages. In the real life we might also do something slightly different such as: copy files from the build context to the container that we are building.</p> <p>Tip</p> <p>Remember: the build context is the directory containing the Dockerfile.</p>"},{"location":"image/dockerfile/copy/#build-some-c-code","title":"Build some C code","text":"<p>In the following simple example we want to build a container that compiles a basic \"Hello world\" program in C.</p> <p>Example, a hello.c:</p> <p><pre><code>#include &lt;stdio.h&gt;\n\nint main () {\n  puts(\"Hello, world!\");\n  return 0;\n}\n</code></pre> We can create a new directory, and put this file in there.</p> <p>Then we will write the Dockerfile and we will use COPY to place the source file into the container</p> <p>Tip</p> <p>On Debian and Ubuntu, the package build-essential will get us a compiler. When installing it, don't forget to specify the -y flag, otherwise the build will fail (since the build cannot be interactive).</p> <pre><code>FROM ubuntu\nRUN apt-get update\nRUN apt-get install -y build-essential\nCOPY hello.c /\nRUN make hello\nCMD /hello\n</code></pre> <p>Exercise:</p> <ul> <li>Create hello.c and Dockerfile in the same directory:</li> <li>Run docker build -t hello . in this directory.</li> <li>Run docker run hello, you should see Hello, world!.</li> </ul>"},{"location":"image/dockerfile/copy/#copy-and-the-build-cache","title":"COPY and the build cache","text":"<p>Docker can cache steps involving COPY. Those steps will not be executed again if the files haven't been changed. You can try it yourself by - Run the build again, but now modify hello.c </p>"},{"location":"image/dockerfile/copy/#the-dockerignore-file","title":"The .dockerignore file","text":"<p>Something you need to take care of is to avoid copy of unneeded files i.e. files in your context but not required in the image. To do that you have a handle: .dockerignore</p> <p>You can create it at the top-level of the build context specifying file names and globs to ignore</p> <p>They won't be sent to the builder and won't end up in the resulting image</p> <p>See the documentation for the little details</p>"},{"location":"image/dockerfile/exercise/","title":"Exercise","text":"<p>The main objective of the exercise is to add a Dockerfile to a Python App. So we have an application and we are asked to do the following: * we need to create a Dockerfile that runs our python application and expose on a well defined port, let's say the 9000. On that port the app will return the environment variable <code>ENVIRONMENT=production</code> ( unless we will ask to return something different ) </p> <p>First of all, let's move on a different root directory called <code>flask</code>:</p> <pre><code>mkdir -p flask\ncd flask\n</code></pre>"},{"location":"image/dockerfile/exercise/#the-app","title":"The App","text":"<p>A simple python3 API that only responds at <code>/</code>. It returns the value of the <code>ENVIRONMENT</code> environment var as JSON. Save the following code in a file named <code>app.py</code>:</p> <pre><code>from flask import Flask\nimport os\nimport sys\n\napp = Flask(__name__)\n\n@app.route(\"/\")\ndef index():\n    env = os.getenv(\"ENVIRONMENT\", None)\n    return {\n        \"env\": env\n    }\n\nif __name__ == \"__main__\":\n    if len(sys.argv) &lt; 2:\n        print(\"Needs port number as a commandline argument.\")\n        sys.exit(1)\n    port = int(sys.argv[1])\n    app.run(host='0.0.0.0', port=port)\n</code></pre> <p>And also, let's add a simple entrypoint that looks like <code>startup.sh</code>:</p> <pre><code>#!/bin/bash\n\npython app.py ${PORT}\n</code></pre>"},{"location":"image/dockerfile/exercise/#the-dependencies","title":"The  Dependencies","text":"<p>Our App has some dependences, so we need to take care of them, here below the list of the software dependences:</p> <pre><code>Click==7.0\nFlask==1.1.1\nitsdangerous==1.1.0\nJinja2==2.11.3\nMarkupSafe==1.1.1\nWerkzeug==0.16.0\n</code></pre> <p>Tip</p> <p>We will Use <code>pip</code> to install the requirements listed in <code>requirements.txt</code>: * <code>pip install -r requirements.txt</code></p>"},{"location":"image/dockerfile/exercise/#running-the-server","title":"Running the server","text":"<p>Of course we want our App be up&amp;running. The server requires one command line argument: the port that it should listen on.  To run the app we need just something like </p> <p><code>python app.py &lt;PORT&gt;</code></p>"},{"location":"image/dockerfile/exercise/#compose-the-dockerfile","title":"Compose the Dockerfile","text":"<p>Let's now build the Dockerfile in order to pack our app</p> <pre><code>FROM python:3.7-slim-buster\n\nRUN apt-get update &amp;&amp; apt-get install -y curl\n\nCOPY requirements.txt /tmp/\n\nRUN pip install -r /tmp/requirements.txt\n\nENV PORT=\"3000\"\nENV ENVIRONMENT=\"prod\" \n\nEXPOSE ${PORT}\n\nRUN useradd --create-home pythonappuser\nWORKDIR /home/pythonappuser\n\nCOPY startup.sh .\nCOPY app.py .\n\nRUN chmod +x startup.sh &amp;&amp; chmod +x app.py &amp;&amp; chown -R pythonappuser:pythonappuser .\nUSER pythonappuser\n\nENTRYPOINT [\"./startup.sh\"]\n</code></pre> <p>Now we can try to build it: </p> <pre><code>docker build -t mycontainerizedapp .\n</code></pre>"},{"location":"image/dockerfile/exercise/#playing-with-our-dockerized-app","title":"Playing with our Dockerized - App","text":"<p>First of all let's check it is doing what is expected. So we should run the container and check that the Python App is actually running. So</p> <pre><code>docker run -d mycontainerizedapp\n</code></pre> <p>now we can get the ID of the container ( you know how to do that now ) and then we can get a bash in to our container: </p> <pre><code>docker exec -ti 9ea45699221b bash\n</code></pre> <p>Now if it is correctly running it should tell us something if we ask someting on its port 3000 ( remmember what we set in our Dockerfile above )</p> <p><pre><code>pythonappuser@9ea45699221b:~$ curl localhost:3000\n{\"env\":\"prod\"}\npythonappuser@9ea45699221b:~$ \n</code></pre> here we go!! it works nicely.  Very good, let's do a step further. We know that we can map the exposed port to the HOST.. so let's do it </p> <p><pre><code>docker run -d -p 3000:3000 mycontainerizedapp \n</code></pre> if it is all working now I shouldn't need to enter the container to check the status of the App on port 3000.. let's try</p> <p><pre><code>curl localhost:3000\n{\"env\":\"prod\"}\n</code></pre> It works. So all is ok. </p> <p>Tip</p> <p>Remember that the <code>EXPOSE</code> instruction does not actually publish the port. It functions as a type of documentation between the person who builds the image and the person who runs the container, about which ports are intended to be published</p> <p>Final step now is about the env variable. Can we re-define it when we startup the continer ? yes we can, remember the -e </p> <pre><code> docker run -d -p 3000:3000 -e ENVIRONMENT=ciccio mycontainerizedapp \n</code></pre> <p>If it worked correctly we should get something different wrt the previous test by querying the port 3000.. let's try: </p> <p><pre><code>curl localhost:3000\n{\"env\":\"ciccio\"}\n</code></pre> ineed! All good! </p>"},{"location":"image/dockerfile/exercise/#optimize-the-building-simple-example","title":"Optimize the building ( simple example )","text":"<p>Now, provided that you got the repo: <code>git clone  https://github.com/spigad/simple-exercise.git</code>  you can try to optimize a bit and use the <code>.dockerignore</code> file. </p> <p>So, you should create the file with the following content:  <pre><code>*.md\n.git*\n</code></pre></p> <p>and then you can check the effect of the <code>.dockerignore</code> by comaparing the <code>Sending build context to Docker daemon</code> with and without. </p>"},{"location":"image/dockerfile/first-dockerfile/","title":"Write the first Dockerfile","text":"<p>A Dockerfile is a build recipe for a Docker image. It contains a series of instructions telling Docker how an image is constructed.</p>"},{"location":"image/dockerfile/first-dockerfile/#our-first-dockerfile","title":"Our first Dockerfile","text":"<p>Our Dockerfile must be in a new, empty directory so first step is to create a directory to hold our Dockerfile.</p> Command <p><pre><code>mkdir myimage\n</code></pre> and now create a Dockerfile inside this directory.</p> Command <p><pre><code>cd myimage\n</code></pre> <pre><code>vim Dockerfile\n</code></pre> (feel fre to choose any editor you like) and add the follwing content: </p> <pre><code>FROM ubuntu:18.04\nRUN apt-get update\nRUN apt-get install -y figlet\n</code></pre> <p>Tip</p> <ul> <li><code>FROM</code> indicates the base image for our build.</li> <li>Each RUN line will be executed by Docker during the build.</li> <li>RUN commands must be non-interactive. (No input can be provided to Docker during the build.) this is why we add the -y flag to apt-get.</li> </ul> <p>Every Dockerfile must start with the FROM instruction. The idea behind is that you need a starting point to build your image. You can start <code>FROM scratch</code>, scratch is an explicitly empty image on the Docker store that is used to build base images such as Alpine a lightweight linux distro that allows you to reduce the overall size of Docker images.</p> <p>Save our file, then execute:</p> Command <pre><code>docker build -t myfiglet .\n</code></pre> <p>Tip</p> <ul> <li><code>-t</code> indicates the tag to apply to the image.</li> <li><code>.</code> indicates the location of the build context.</li> </ul> <p>The output you will get is something like the follwing </p> <pre><code>Sending build context to Docker daemon  2.048kB\nStep 1/3 : FROM ubuntu:18.04\n ---&gt; 81bcf752ac3d\nStep 2/3 : RUN apt-get update\n ---&gt; Running in 9f07f31f5608\n...(..cut RUN output..)...\nReading package lists...\nRemoving intermediate container 9f07f31f5608\n ---&gt; e2ed94338e24\nStep 3/3 : RUN apt-get install figlet\n ---&gt; Running in 9548f425acac\nReading package lists...\n...(..cut RUN output..)...\nRemoving intermediate container 9548f425acac\n ---&gt; d9c8c229f154\nSuccessfully built d9c8c229f154\nSuccessfully tagged myfiglet:latest\n</code></pre> <p>Let's analyze the oputput: </p> <p><code>Sending build context to Docker daemon 2.048 kB</code></p> <ul> <li>The build context is the . directory given to docker build.<ul> <li>It is sent (as an archive) by the Docker client to the Docker daemon.<ul> <li>This allows to use a remote machine to build using local files.</li> </ul> </li> <li>Be careful (or patient) if that directory is big and your link is slow.<ul> <li>You can speed up the process with a .dockerignore file which tells docker to ignore specific files in the directory, ignore files that you won't need in the build context!</li> </ul> </li> </ul> </li> </ul> <pre><code>Step 2/3 : RUN apt-get update\n ---&gt; Running in 9f07f31f5608\n...(..cut RUN output..)...\nReading package lists...\nRemoving intermediate container 9f07f31f5608\n ---&gt; e2ed94338e24\n</code></pre> <p>A container (9f07f31f5608) is created from the base image. </p> <ul> <li>The RUN command is executed in this container.</li> <li>The container is committed into an image (e2ed94338e24).</li> <li>The build container (9f07f31f5608) is removed.</li> <li>The output of this step will be the base image for the next one.</li> </ul> <p>Tip</p> <ul> <li>After each build step, Docker takes a snapshot of the resulting image and before executing a step, Docker checks if it has already built the same sequence. Docker uses the exact strings defined in your Dockerfile, so the following two are not the same!</li> <li>RUN apt-get install figlet cowsay</li> <li>RUN apt-get install cowsay figlet   </li> </ul> <p>You can force a rebuild with docker build --no-cache ....</p> <p>And to close the loop: (only) <code>RUN</code>, <code>COPY</code> and <code>ADD</code> instructions create layers to improve build performance. The main advantage of image layering lies in image caching.</p>"},{"location":"image/dockerfile/first-dockerfile/#running-the-image","title":"Running the image","text":"<p>The resulting image is not different from the one produced manually. :)</p> <p><pre><code>docker run -ti myfiglet  bash\n</code></pre> and issue something like:  <pre><code>root@4d7d8ec44135:/# figlet ciao ciao \n      _                    _             \n  ___(_) __ _  ___     ___(_) __ _  ___  \n / __| |/ _` |/ _ \\   / __| |/ _` |/ _ \\ \n| (__| | (_| | (_) | | (__| | (_| | (_) |\n \\___|_|\\__,_|\\___/   \\___|_|\\__,_|\\___/ \n\nroot@4d7d8ec44135:/# \n</code></pre></p>"},{"location":"image/dockerfile/instructions/","title":"Overview of basic instructions","text":"<p>We\u2019ll cover the following basic instructions to get you started:</p> <ul> <li>FROM - every Dockerfile starts with FROM, with the introduction of multi-stage builds, you can have more than one FROM instruction in one Dockerfile.</li> <li>COPY vs ADD - Add directories and files to your Docker image. ( Sometime confuesd... )</li> <li>ENV - set environment variables.</li> <li>RUN - let\u2019s run commands.</li> <li>USER - when root is too mainstream.</li> <li>WORKDIR - set the working directory.</li> <li>EXPOSE - get your ports right.</li> </ul>"},{"location":"image/dockerfile/instructions/#from","title":"FROM","text":"<p>Every Dockerfile must start with the FROM instruction in the form of FROM <code>&lt;image&gt;[:tag]</code>. This will set the base image for your Dockerfile, which means that subsequent instructions will be applied to this base image.</p> <p>The tag value is optional, if you don\u2019t specify the tag Docker will use the tag latest and will try and use or pull the latest version of the base image during build.</p> <p>On the little bit more advanced side, let\u2019s note the following:</p> <p>There is one instruction that you can put before FROM into your Dockerfile. This instruction is ARG. ARG is used to specify arguments for the docker build command with the --build-arg <code>&lt;varname&gt;=&lt;value&gt;</code> flag. You can have more than one FROM instructions in your Dockerfile. You will want to use this feature, for example, when you use one base image to build your app and another base image to run it. It\u2019s called a multi-stage build and you can read about it here.</p> <p>This is why every section that starts with FROM in your Dockerfile is called a build stage (even in the simple case of having only one FROM instruction). You can specify the name of the build stage in the form <code>FROM &lt;image&gt;[:tag] [AS &lt;name&gt;]</code>.</p>"},{"location":"image/dockerfile/instructions/#copy-vs-add","title":"COPY vs ADD","text":"<p>Both ADD and COPY are designed to add directories and files to your Docker image in the form of <code>ADD &lt;src&gt;... &lt;dest&gt;</code> or <code>COPY &lt;src&gt;... &lt;dest&gt;</code>. Most resources, suggest to use COPY.</p> <p>The reason behind this is that ADD has extra features compared to COPY that make ADD more unpredictable and a bit over-designed. ADD can pull files from url sources, which COPY cannot. ADD can also extract compressed files assuming it can recognize and handle the format. You cannot extract archives with COPY.</p> <p>The ADD instruction was added to Docker first, and COPY was added later to provide a straightforward, rock solid solution for copying files and directories into your container\u2019s file system.</p> <p>If you want to pull files from the web into your image I would suggest to use RUN and curl and uncompress your files with RUN and commands you would use on the command line.</p>"},{"location":"image/dockerfile/instructions/#env","title":"ENV","text":"<p>ENV is used to define environment variables. The interesting thing about ENV is that it does two things:</p> <ul> <li>You can use it to define environment variables that will be available in your container. So when you build an image and start up a container with that image you\u2019ll find that the environment variable is available and is set to the value you specified in the Dockerfile.</li> <li>You can use the variables that you specify by ENV in the Dockerfile itself. So in subsequent instructions the environment variable will be available.</li> </ul>"},{"location":"image/dockerfile/instructions/#run","title":"RUN","text":"<p>RUN will execute commands, so it\u2019s one of the most-used instructions. I would like to highlight two points:</p> <ul> <li>You\u2019ll use a lot of apt-get type of commands to add new packages to your image. It\u2019s always advisable to put apt-get update and apt-get install commands on the same line. This is important because of layer caching. Having these on two separate lines would mean that if you add a new package to your install list, the layer with apt-get update will not be invalidated in the layer cache and you might end up in a mess. Read more here.</li> <li>RUN has two forms; <code>RUN &lt;command&gt;</code> (called shell form) and <code>RUN [\"executable\", \"param1\", \"param2\"]</code> called exec form. Please note that <code>RUN &lt;command&gt;</code> will invoke a shell automatically (/bin/sh -c by default), while the exec form will not invoke a command shell. </li> </ul>"},{"location":"image/dockerfile/instructions/#user","title":"USER","text":"<p>Don\u2019t run your stuff as root, use the USER instruction to specify the user. This user will be used to run any subsequent RUN, CMD AND ENDPOINT instructions in your Dockerfile.</p>"},{"location":"image/dockerfile/instructions/#workdir","title":"WORKDIR","text":"<p>A very convenient way to define the working directory, it will be used with subsequent RUN, CMD, ENTRYPOINT, COPY and ADD instructions. You can specify WORKDIR multiple times in a Dockerfile.</p> <p>If the directory does not exists, Docker will create it for you.</p>"},{"location":"image/dockerfile/instructions/#expose","title":"EXPOSE","text":"<p>An important instruction to inform your users about the ports your application is listening on. EXPOSE will not publish the port, you need to use docker run -p... to do that when you start the container.</p>"},{"location":"image/dockerfile/instructions/#cmd-and-entrypoint","title":"CMD and ENTRYPOINT","text":"<p>CMD is the instruction to specify what component is to be run by your image with arguments in the following form: CMD [\u201cexecutable\u201d, \u201cparam1\u201d, \u201cparam2\u201d\u2026].</p> <p>You can override CMD when you\u2019re starting up your container by specifying your command after the image name like this: <code>$ docker run [OPTIONS] IMAGE[:TAG|@DIGEST] [COMMAND] [ARG...]</code>.</p> <p>You can only specify one CMD in a Dockerfile (OK, physically you can specify more than one, but only the last one will be used).</p> <p>So what\u2019s the deal with ENTRYPOINT? When you specify an entry point, your image will work a bit differently. You use ENTRYPOINT as the main executable of your image. In this case whatever you specify in CMD will be added to ENTRYPOINT as parameters.</p>"},{"location":"image/intro/","title":"Building interactively","text":"<p>This is a quick recap of things that you already saw in the Part-1. The following steps guide you toward the interactive image building process. </p>"},{"location":"image/intro/#getting-an-image-and-apply-some-changes","title":"Getting an image and apply some changes","text":"Command <pre><code>docker run -it ubuntu:18.04\n</code></pre> <p>You will get something like the following output:</p> <pre><code>Unable to find image 'ubuntu:18.04' locally\n18.04: Pulling from library/ubuntu\n4bbfd2c87b75: Pull complete \nd2e110be24e1: Pull complete \n889a7173dcfe: Pull complete \nDigest: sha256:67b730ece0d34429b455c08124ffd444f021b81e06fa2d9cd0adaf0d0b875182\nStatus: Downloaded newer image for ubuntu:18.04\nroot@844ec9e540a5:/#\n</code></pre> <p>Run the command apt-get update to refresh the list of packages available to install. For this simple exercise we will use Figlet</p> <p>Then run the command apt-get install figlet to install the program we are interested in.</p> Command <pre><code>apt-get update &amp;&amp; apt-get install figlet\n</code></pre> <p>You will get something like the following output:</p> <pre><code>root@844ec9e540a5:/# apt-get update &amp;&amp; apt-get install figlet\nGet:1 http://archive.ubuntu.com/ubuntu bionic InRelease [242 kB]\nGet:2 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\nGet:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]         \nGet:4 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]                   \nGet:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 Packages [1344 kB]                    \nGet:6 http://archive.ubuntu.com/ubuntu bionic/restricted amd64 Packages [13.5 kB]                         \nGet:7 http://archive.ubuntu.com/ubuntu bionic/multiverse amd64 Packages [186 kB]                          \nGet:8 http://archive.ubuntu.com/ubuntu bionic/universe amd64 Packages [11.3 MB]                           \nGet:9 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [33.5 kB]                 \nGet:10 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [481 kB]\nGet:11 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2619 kB]\nGet:12 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2185 kB]\nGet:13 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [11.4 kB]\nGet:14 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [11.3 kB]\nGet:15 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1415 kB]\n...\n...\n</code></pre>"},{"location":"image/intro/#check-the-differences-with-respect-to-the-original-image","title":"Check the differences with respect to the original image","text":"<p>Once done type exit at the container prompt to leave the interactive session. Now let's run docker diff to see the difference between the base image and our container.</p> Command <pre><code>docker diff 844ec9e540a5\n</code></pre> <p>Tip</p> <p>Remember: you need to use your container ID. In order to get it you can always use <code>docker ps -a</code></p> <p>and the output you will get is something like</p> <pre><code>C /root\nA /root/.bash_history\nC /etc\nA /etc/emacs\nA /etc/emacs/site-start.d\nA /etc/emacs/site-start.d/50figlet.el\nC /etc/alternatives\nA /etc/alternatives/figlet\nC /usr\nC /usr/share\nA /usr/share/figlet\nA /usr/share/figlet/646-ca.flc\nA /usr/share/figlet/646-ca2.flc\nA /usr/share/figlet/646-hu.flc\n</code></pre> <p>Tip</p> <p>Three different types of change are tracked by <code>docker diff</code>:     -<code>A</code> A file or directory was added     -<code>D</code> A file or directory was deleted     -<code>C</code> A file or directory was changed</p>"},{"location":"image/intro/#commit-the-changes-and-use-your-image","title":"Commit the changes and use your image","text":"<p>The last step is now to commit the changes, that way we will create a new layer with the changes we made before, and a new image using this new layer.</p> Command <pre><code>docker commit 844ec9e540a5 interactivefiglet\n</code></pre> <p>Here we go!  we have build our first image interactively! Let's run it and test it</p> Command <pre><code>docker run -ti interactivefiglet \n</code></pre> <p>once you entered the container you can type  something like the following:</p> Command <p><pre><code>figlet ciao ciao \n</code></pre> you will get your expected output: </p> <pre><code>      _                    _             \n  ___(_) __ _  ___     ___(_) __ _  ___  \n / __| |/ _` |/ _ \\   / __| |/ _` |/ _ \\ \n| (__| | (_| | (_) | | (__| | (_| | (_) |\n \\___|_|\\__,_|\\___/   \\___|_|\\__,_|\\___/ \n\nroot@be9e5e08db21:/#\n</code></pre> <p>Tip</p> <p>in one line command you could have typed the following with the same result: <code>docker run interactivefiglet figlet ciao ciao</code></p> <p>This is ok for quick &amp; dirty test and playground .. but what about if we need to be reproducible, automated ?  To this end we need to learn the build process by writing a Dockerfile.</p>"},{"location":"image/multistage/multistage-example/","title":"Our first multi-stage Dockerfile","text":"<p>The objective here is to try to use multi-stage images in practice. To this end we will change our Dockerfile to:</p> <ul> <li> <p>give a nickname to the first stage: compiler</p> </li> <li> <p>add a second stage using the same ubuntu base image</p> </li> <li> <p>add the hello binary to the second stage</p> </li> <li> <p>make sure that CMD is in the second stage</p> </li> </ul>"},{"location":"image/multistage/multistage-example/#mulit-stage-docker-file-example","title":"Mulit-stage Docker file: example","text":"<p>Here is the final Dockerfile:</p> <p><pre><code>FROM gcc:9.5.0 AS compiler\nADD https://raw.githubusercontent.com/docker-library/hello-world/master/hello.c  /hello.c\nRUN make hello\nFROM ubuntu\nCOPY --from=compiler /hello /hello\nCMD /hello\n</code></pre> Let's build it, and check that it works correctly: <pre><code>docker build -t hellomultistage .\n</code></pre></p> <p>and now we can test: </p> <pre><code>docker run hellomultistage\n</code></pre>"},{"location":"image/multistage/multistage-example/#home-work","title":"Home work","text":"<p>List our images with docker images, and check the size of:</p> <ul> <li> <p>The ubuntu base image,</p> </li> <li> <p>The single-stage hello image,</p> </li> <li> <p>The multi-stage hellomultistage image.</p> </li> </ul> <p>We can achieve even smaller images if we use smaller base images ( i.e. Apline etc ) </p>"},{"location":"image/registry/dockerhub/","title":"Publishing images to the Docker hub","text":"<p>Now that we have built our first images, we can publish them to the Docker Hub!</p>"},{"location":"image/registry/dockerhub/#logging-into-our-docker-hub-account","title":"Logging into our Docker Hub account","text":"<pre><code>docker login\n</code></pre> <p>This requires an account on the Docker Hub ( which is free as well as storing the images it is free ). So if you have one you can try a thus you'll see a output  like this:  <pre><code>Login with your Docker ID to push and pull images from Docker Hub. If you don't have a Docker ID, head over to https://hub.docker.com to create one.\nUsername: spiga\nPassword: \nWARNING! Your password will be stored unencrypted in /home/tutor5/.docker/config.json.\nConfigure a credential helper to remove this warning. See\nhttps://docs.docker.com/engine/reference/commandline/login/#credentials-store\n\nLogin Succeeded\n</code></pre></p>"},{"location":"image/registry/dockerhub/#tagging-an-image-to-push-it-on-the-hub","title":"Tagging an image to push it on the Hub","text":"<p>Docker images tags are like Git tags and branches, like bookmarks pointing at a specific image ID.</p> <p>Tagging an image doesn't rename an image: it adds another tag. When pushing an image to a registry, the registry address is in the tag.</p> <ul> <li> <p><code>Example: registry.example.net:5000/image</code></p> <ul> <li>spiga/test is  index.docker.io/spiga/test</li> <li>ubuntu is index.docker.io/library/ubuntu</li> </ul> </li> </ul>"},{"location":"image/registry/dockerhub/#lets-tag-our-myfiglet-image","title":"Let's tag our myfiglet image","text":"<p>Or please do it with any other image you like. Let's look for the image to tag: </p> <pre><code>\n$docker images \n\nREPOSITORY                    TAG               IMAGE ID       CREATED          SIZE\nmyfiglet                      latest            cabcb70593be   15 seconds ago   103MB\nmycontainerizedapp            latest            b64faab26e8f   30 hours ago     147MB\npython                        3.7-slim-buster   867339bd5033   2 weeks ago      113MB\nubuntu                        18.04             81bcf752ac3d   3 weeks ago      63.1MB\ngcr.io/k8s-minikube/kicbase   v0.0.22           bcd131522525   5 weeks ago      1.09GB\nubuntu                        latest            7e0aa2d69a15   7 weeks ago      72.7MB\n</code></pre> <p>Ok let's tag the <code>myfiglet</code></p> <pre><code>docker tag myfiglet spiga/myfiglet\n</code></pre> <p>and check what's happening now: </p> <pre><code>\ndocker images \nREPOSITORY                    TAG               IMAGE ID       CREATED              SIZE\nmyfiglet                      latest            cabcb70593be   About a minute ago   103MB\nspiga/myfiglet                latest            cabcb70593be   About a minute ago   103MB\nmycontainerizedapp            latest            b64faab26e8f   30 hours ago         147MB\npython                        3.7-slim-buster   867339bd5033   2 weeks ago          113MB\nubuntu                        18.04             81bcf752ac3d   3 weeks ago          63.1MB\ngcr.io/k8s-minikube/kicbase   v0.0.22           bcd131522525   5 weeks ago          1.09GB\nubuntu                        latest            7e0aa2d69a15   7 weeks ago          72.7MB\n</code></pre> <p>Ok so we are ready to push it on Dockerhub  <pre><code>docker push spiga/myfiglet \n</code></pre> and the output will look like something this one </p> <pre><code>Using default tag: latest\nThe push refers to repository [docker.io/spiga/myfiglet]\nf0f9028d0afb: Pushed \n3ee587de5e03: Pushed \n2f140462f3bc: Mounted from library/ubuntu \n63c99163f472: Mounted from library/ubuntu \nccdbb80308cc: Mounted from library/ubuntu \nlatest: digest: sha256:ec988085cd4d5efa6bdb5b26a3694eff2c6e26032521c4b6cb248b4efb0f5f51 size: 1365\n</code></pre> <p>Ok, very good! That's it!</p> <p>Anybody can now docker run spiga/myfiglet anywhere.</p>"},{"location":"image/registry/dockerhub/#quick-check","title":"Quick check","text":"<p>Now if we remove the image on local filesystem and the we get it back from the registry ( DockerHub ) we can see how it works and we close the loop. </p> <p>Tip</p> <p>To remove the image : <code>docker rmi IMAGE ID</code>. To get the <code>IMAGE ID</code> just use <code>docker images</code></p> <pre><code>\ndocker pull spiga/myfiglet\n\nUsing default tag: latest\nlatest: Pulling from spiga/myfiglet\n345e3491a907: Already exists \n57671312ef6f: Already exists \n5e9250ddb7d0: Already exists \nd9dac9d5417f: Pull complete \nbdf8f857644c: Pull complete \nDigest: sha256:ec988085cd4d5efa6bdb5b26a3694eff2c6e26032521c4b6cb248b4efb0f5f51\nStatus: Downloaded newer image for spiga/myfiglet:latest\ndocker.io/spiga/myfiglet:latest"},{"location":"intro/container/","title":"Docker container lifecycle","text":"<p> Source: https://twitter.com/pierrecdn/status/620587662928424960</p> <ul> <li>docker create command will create a new Docker container with the specified docker image.   <pre><code>   docker create --name &lt;container name&gt; &lt;image name&gt;\n</code></pre></li> <li>docker start command can be used to start a stopped container.   <pre><code>docker start &lt;container name&gt;\n</code></pre></li> <li>docker run command does the work of both docker create and docker start command.   <pre><code>docker run -it --name &lt;container name&gt; &lt;image name&gt;\n</code></pre></li> <li>docker pause command can be used to pause the processes running inside the container (a SIGSTOP signal will be sent to the main process).   <pre><code>docker pause &lt;container name&gt;\n</code></pre></li> <li>docker unpause command allows to unpause the container.   <pre><code>   docker unpause &lt;container name&gt;\n</code></pre></li> <li>docker stop command can be used to stop all the processes running in the container: the main process inside the container receives a SIGTERM signal.   <pre><code>   docker stop &lt;container name&gt;\n</code></pre></li> <li>docker rm command is used to destroy a stopped container (with <code>--force</code> option you can destroy a running container, but it's better to stop it before)   <pre><code>docker rm &lt;container name&gt;\n</code></pre></li> <li>docker kill command will kill all the processes in the container: the main process will be sent a SIGKILL or any signal specified with option <code>\u2013signal</code>.   <pre><code>   docker kill &lt;container name&gt;  \n</code></pre></li> </ul>"},{"location":"intro/container/#docker-command-syntax","title":"Docker command syntax","text":"<p>Prior to version 1.13, Docker had only the previously mentioned command syntax. Later on, the command-line was restructured to have the following syntax:</p> <pre><code>docker &lt;object&gt; &lt;command&gt; &lt;options&gt;\n</code></pre> <p>In this syntax:</p> <ul> <li><code>object</code> indicates the type of Docker object you'll be manipulating. This can be a container, image, network or volume object.</li> <li><code>command</code> indicates the task to be carried out by the daemon, that is the run command.</li> <li><code>options</code> can be any valid parameter that can override the default behavior of the command, like the <code>--publish</code> option for port mapping.</li> </ul> <p>The commands in the previous sections can be re-written as <code>docker container &lt;command&gt;</code>, e.g. <code>docker container create</code> or <code>docker container run</code>.</p> <p>To learn more about the available commands, visit the official documentation.</p>"},{"location":"intro/hello-world/","title":"Run your first container","text":"<p>Let's create our first docker container:</p> Command <p><pre><code>docker container run hello-world\n</code></pre> Look at the output:</p> <pre><code>Unable to find image 'hello-world:latest' locally\nlatest: Pulling from library/hello-world\nc1ec31eb5944: Pull complete\nDigest: sha256:53cc4d415d839c98be39331c948609b659ed725170ad2ca8eb36951288f81b75\nStatus: Downloaded newer image for hello-world:latest\n\nHello from Docker!\nThis message shows that your installation appears to be working correctly.\n\nTo generate this message, Docker took the following steps:\n 1. The Docker client contacted the Docker daemon.\n 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.\n    (amd64)\n 3. The Docker daemon created a new container from that image which runs the\n    executable that produces the output you are currently reading.\n 4. The Docker daemon streamed that output to the Docker client, which sent it\n    to your terminal.\n\nTo try something more ambitious, you can run an Ubuntu container with:\n $ docker run -it ubuntu bash\n\nShare images, automate workflows, and more with a free Docker ID:\n https://hub.docker.com/\n\nFor more examples and ideas, visit:\n https://docs.docker.com/get-started/\n</code></pre> <p>Let's see what happened behind the scene...</p> <p></p> <p>You launched the command <code>docker run hello-world</code> where <code>hello-world</code> is the name of a docker image.</p> <p>The Docker client reached out to the daemon, telling it to get the hello-world image and run a container from that.</p> <p>The Docker daemon looked for the image within your local repository and realized that it's not there: <code>Unable to find image 'hello-world:latest' locally</code>.</p> <p>The daemon then contacted the default public registry which is Docker Hub and pulled in the latest copy of the <code>hello-world</code> image: <code>Pulling from library/hello-world</code>.</p> <p>The Docker daemon then created a new container from the freshly pulled image.</p> <p>Finally the Docker daemon ran the container created using the hello-world image.</p> <p>Hello World only function is to output the text you see in the terminal, after which the container exits.</p> <p>You can use the command <code>docker container ps</code> to list the running containers (use <code>-a</code> option to list all the stopped containers): <pre><code>docker container ps -a\n</code></pre></p> <p>You will find the container just started and run from the <code>hello-world</code> image: <pre><code>CONTAINER ID   IMAGE         COMMAND    CREATED              STATUS                          PORTS     NAMES\nc0ba7d45168a   hello-world   \"/hello\"   About a minute ago   Exited (0) About a minute ago             thirsty_poitras\n</code></pre></p> <p>Note</p> <p>When we create a container, if we don't give a specific name, Docker will pick one for us.</p> <p>It will be the concatenation of:</p> <ul> <li>A mood (furious, goofy, suspicious, boring...)</li> <li>The name of a famous inventor (tesla, darwin, wozniak...)</li> </ul> <p>Examples: <code>happy_curie</code>, <code>jovial_lovelace</code> ...</p>"},{"location":"intro/images/","title":"Where are Docker images stored?","text":"<p>The storage location of Docker images and containers depends on the operating system. The command <code>docker info</code> provides information about your Docker configuration, including the <code>Storage Driver</code> and the <code>Docker Root Dir</code>.</p> <p>On Ubuntu, Docker stores images and containers files under <code>/var/lib/docker</code>:</p> <pre><code>total 44\ndrwx--x--x 4 root root 4096 Sep  4 10:46 buildkit\ndrwx--x--- 3 root root 4096 Sep  4 10:53 containers\n-rw------- 1 root root   36 Sep  4 10:46 engine-id\ndrwx------ 3 root root 4096 Sep  4 10:46 image\ndrwxr-x--- 3 root root 4096 Sep  4 10:46 network\ndrwx--x--- 6 root root 4096 Sep  4 10:53 overlay2\ndrwx------ 4 root root 4096 Sep  4 10:46 plugins\ndrwx------ 2 root root 4096 Sep  4 10:46 runtimes\ndrwx------ 2 root root 4096 Sep  4 10:46 swarm\ndrwx------ 2 root root 4096 Sep  4 10:53 tmp\ndrwx-----x 2 root root 4096 Sep  4 10:46 volumes\n</code></pre> <p>Docker images are stored in <code>/var/lib/docker/overlay2</code>.</p> <p>Let's explore the content of our image <code>hello-world</code>:</p> Info <p>The command <code>docker inspect</code> returns low-level information on Docker objects (images, containers, networks, etc.).</p> <p>More info in the Docker official doc.</p> <pre><code>docker image inspect hello-world\n</code></pre> <pre><code>[\n    {\n        \"Id\": \"sha256:d2c94e258dcb3c5ac2798d32e1249e42ef01cba4841c2234249495f87264ac5a\",\n        \"RepoTags\": [\n            \"hello-world:latest\"\n        ],\n....\n        \"GraphDriver\": {\n            \"Data\": {\n                \"MergedDir\": \"/var/lib/docker/overlay2/7fea1105b18fd2b9fb8237cd6ff7bf2e2ba1521012006625ef2b1542e9b5f285/merged\",\n                \"UpperDir\": \"/var/lib/docker/overlay2/7fea1105b18fd2b9fb8237cd6ff7bf2e2ba1521012006625ef2b1542e9b5f285/diff\",\n                \"WorkDir\": \"/var/lib/docker/overlay2/7fea1105b18fd2b9fb8237cd6ff7bf2e2ba1521012006625ef2b1542e9b5f285/work\"\n            },\n            \"Name\": \"overlay2\"\n        },\n....\n</code></pre> <p>The <code>GraphDriver.Data</code> dictionary contains information about the layers of the image.</p> <p>In general, the LowerDir contains the read-only layers of an image. The read-write layer that represents changes are part of the UpperDir.</p> <p>The <code>hello-world</code> image is built starting from the base image <code>scratch</code> that is an explicitly empty image. </p> <p>The <code>hello-world</code> image therefore contains just one layer that adds the <code>hello</code> executable (statically linked) to the base empty image. </p> <p>Look at the content of the UpperDir:</p> <pre><code>sudo ls -latr /var/lib/docker/overlay2/7fea1105b18fd2b9fb8237cd6ff7bf2e2ba1521012006625ef2b1542e9b5f285/diff \ntotal 24\n-rwxr-xr-x 1 root root 13256 Dec 15  2023 hello\ndrwxr-xr-x 2 root root  4096 Sep  4 10:53 .\ndrwx--x--- 3 root root  4096 Sep  4 10:53 ..\n</code></pre> <p>Another interesting command is <code>docker history</code> that shows the hystory of an image. Try it!</p> <pre><code>docker history hello-world\n</code></pre> <p>Output: <pre><code>IMAGE          CREATED         CREATED BY                SIZE      COMMENT\nd2c94e258dcb   16 months ago   CMD [\"/hello\"]            0B        buildkit.dockerfile.v0\n&lt;missing&gt;      16 months ago   COPY hello / # buildkit   13.3kB    buildkit.dockerfile.v0\n</code></pre></p> <p>Again, you can see here that the image has only one layer (0B lines are neglected).</p>"},{"location":"intro/info/","title":"Docker info","text":"<p>You can get the basic information about your Docker configuration by executing:</p> Command <pre><code>docker info\n</code></pre> <p>You will get something like the following output:</p> <pre><code>Client: Docker Engine - Community\n Version:    27.2.0\n Context:    default\n Debug Mode: false\n Plugins:\n  buildx: Docker Buildx (Docker Inc.)\n    Version:  v0.16.2\n    Path:     /usr/libexec/docker/cli-plugins/docker-buildx\n  compose: Docker Compose (Docker Inc.)\n    Version:  v2.29.2\n    Path:     /usr/libexec/docker/cli-plugins/docker-compose\n\nServer:\n Containers: 0\n  Running: 0\n  Paused: 0\n  Stopped: 0\n Images: 0\n Server Version: 27.2.0\n Storage Driver: overlay2\n  Backing Filesystem: extfs\n  Supports d_type: true\n  Using metacopy: false\n  Native Overlay Diff: true\n  userxattr: false\n Logging Driver: json-file\n Cgroup Driver: systemd\n Cgroup Version: 2\n Plugins:\n  Volume: local\n  Network: bridge host ipvlan macvlan null overlay\n  Log: awslogs fluentd gcplogs gelf journald json-file local splunk syslog\n Swarm: inactive\n Runtimes: runc io.containerd.runc.v2\n Default Runtime: runc\n Init Binary: docker-init\n containerd version: 472731909fa34bd7bc9c087e4c27943f9835f111\n runc version: v1.1.13-0-g58aa920\n init version: de40ad0\n Security Options:\n  apparmor\n  seccomp\n   Profile: builtin\n  cgroupns\n Kernel Version: 6.8.0-40-generic\n Operating System: Ubuntu 24.04 LTS\n OSType: linux\n Architecture: x86_64\n CPUs: 2\n Total Memory: 3.824GiB\n Name: tutorvm-1\n ID: 56833310-4f20-4141-9869-f6ff1e988f66\n Docker Root Dir: /var/lib/docker\n Debug Mode: false\n Experimental: false\n Insecure Registries:\n  127.0.0.0/8\n Live Restore Enabled: false\n</code></pre> <p>The output contains information about your storage driver, your docker root directory, the supported plugins (volume, network, log), the default registry, etc.</p>"},{"location":"intro/install/","title":"Install docker engine on Ubuntu","text":"<p>We will install docker engine on our Ubuntu Noble 24.04 (LTS) Virtual Machine using the repository.</p> <p>Info</p> <p>Full instructions are available at https://docs.docker.com/engine/install/</p>"},{"location":"intro/install/#setup-the-repository","title":"Setup the repository","text":"<ol> <li> <p>Update the apt package index and install packages to allow apt to use a repository over HTTPS:    <pre><code>sudo apt-get update\n\nsudo apt-get install \\\n    ca-certificates \\\n    curl \\\n    gnupg \\\n</code></pre></p> </li> <li> <p>Add Docker\u2019s official GPG key: <pre><code> sudo mkdir -p /etc/apt/keyrings\n curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg\n</code></pre></p> </li> <li> <p>Use the following command to set up the repository: <pre><code>echo \\\n  \"deb [arch=\"$(dpkg --print-architecture)\" signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\\n  \"$(. /etc/os-release &amp;&amp; echo \"$VERSION_CODENAME\")\" stable\" | \\\n  sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n</code></pre></p> </li> </ol>"},{"location":"intro/install/#install-docker-engine","title":"Install Docker Engine","text":"<p>Update the apt package index, and install the latest version of Docker Engine, containerd, and Docker Compose, or go to the next step to install a specific version:</p> <pre><code> sudo apt-get update\n sudo apt-get install docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n</code></pre>"},{"location":"intro/install/#post-installation-steps","title":"Post-installation steps","text":"<p>The Docker daemon binds to a Unix socket instead of a TCP port. By default that Unix socket is owned by the user <code>root</code> and other users can only access it using <code>sudo</code>. The Docker daemon always runs as the <code>root</code> user.</p> <p>If you don\u2019t want to preface the <code>docker</code> command with <code>sudo</code>, add users to the Unix group <code>docker</code>. When the Docker daemon starts, it creates a Unix socket accessible by members of the <code>docker</code> group.</p> <ul> <li>Add your user to the docker group.</li> </ul> <pre><code>sudo usermod -aG docker $USER\n</code></pre> <ul> <li>Log out and log back in so that your group membership is re-evaluated.</li> </ul>"},{"location":"intro/install/#verify","title":"Verify","text":"CommandExample output <pre><code>docker --version\n</code></pre> <pre><code>Docker version 27.2.0, build 3ab4256    \n</code></pre>"},{"location":"networking/networking/","title":"Bridge mode and port mapping","text":"<p>Let's start from a new nginx docker container:</p> <pre><code>docker container run -d --name nginx nginx\n</code></pre> <p>The <code>inspect</code> command provided details about the networking configuration of the container:</p> <pre><code>...\n            \"Networks\": {\n                \"bridge\": {\n                    \"IPAMConfig\": null,\n                    \"Links\": null,\n                    \"Aliases\": null,\n                    \"NetworkID\": \"0aa786b7de5fbfcd3e18db78511ed544d450bb0ad198cab0244bc8b83d30b514\",\n                    \"EndpointID\": \"c3b64e072f7851e3bf55ba3685fa1fbdec6b9c59d18ae27e5e90a1be5728f54c\",\n                    \"Gateway\": \"172.17.0.1\",\n                    \"IPAddress\": \"172.17.0.2\",\n                    \"IPPrefixLen\": 16,\n                    \"IPv6Gateway\": \"\",\n                    \"GlobalIPv6Address\": \"\",\n                    \"GlobalIPv6PrefixLen\": 0,\n                    \"MacAddress\": \"02:42:ac:11:00:02\",\n                    \"DriverOpts\": null\n                }\n            }\n...\n</code></pre> <p>To list out the networks in your system, execute the following command:</p> CommandOutput <pre><code>docker network ls \n</code></pre> <pre><code>NETWORK ID     NAME      DRIVER    SCOPE\n0aa786b7de5f   bridge    bridge    local\n19747c3d0c9a   host      host      local\n36dc4ef5b900   none      null      local\n</code></pre> <p>As you can see, our container is attached to the default bridge network <code>0aa786b7de5f</code> (long ID: 0aa786b7de5fbfcd3e18db78511ed544d450bb0ad198cab0244bc8b83d30b514). We get more details about this network with the <code>inspect</code> command:</p> CommandOutput <pre><code>docker network inspect 0aa786b7de5f\n</code></pre> <pre><code>[\n    {\n        \"Name\": \"bridge\",\n        \"Id\":   \"0aa786b7de5fbfcd3e18db78511ed544d450bb0ad198cab0 244bc8b83d30b514\",\n        \"Created\": \"2021-05-27T13:27:32.164161898Z\",\n        \"Scope\": \"local\",\n        \"Driver\": \"bridge\",\n        \"EnableIPv6\": false,\n        \"IPAM\": {\n            \"Driver\": \"default\",\n            \"Options\": null,\n            \"Config\": [\n                {\n                    \"Subnet\": \"172.17.0.0/16\",\n                    \"Gateway\": \"172.17.0.1\"\n                }\n            ]\n        },\n        \"Internal\": false,\n        \"Attachable\": false,\n        \"Ingress\": false,\n        \"ConfigFrom\": {\n            \"Network\": \"\"\n        },\n        \"ConfigOnly\": false,\n        \"Containers\": {\n            \"2f03f1f2cd100ec584349124a93f180fa743d1c3ab7b   cc31c9d8156225d6f06a\": {\n                \"Name\": \"nginx\",\n                \"EndpointID\":   \"c3b64e072f7851e3bf55ba3685fa1fbdec6b9c59 d18ae27e5e90a1be5728f54c\",\n                \"MacAddress\": \"02:42:ac:11:00:02\",\n                \"IPv4Address\": \"172.17.0.2/16\",\n                \"IPv6Address\": \"\"\n            }\n        },\n        \"Options\": {\n            \"com.docker.network.bridge.default_bridge\":     \"true\",\n            \"com.docker.network.bridge.enable_icc\":     \"true\",\n            \"com.docker.network.bridge. enable_ip_masquerade\": \"true\",\n            \"com.docker.network.bridge. host_binding_ipv4\": \"0.0.0.0\",\n            \"com.docker.network.bridge.name\": \"docker0\",\n            \"com.docker.network.driver.mtu\": \"1500\"\n        },\n        \"Labels\": {}\n    }\n]\n</code></pre> <p>We can see that the container has an IP address of <code>172.17.0.2</code> and uses the gateway address of the <code>docker0</code> interface.</p> <p>Now we know that our nginx service is running on port 80 inside the container. </p> <p>Indeed we can contact our service on port <code>80</code> using the IP <code>172.17.0.2</code>, try the following command from your docker host:</p> CommandOutput <pre><code>curl http://172.17.0.2:80\n</code></pre> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;Welcome to nginx!&lt;/title&gt;\n&lt;style&gt;\n    body {\n        width: 35em;\n        margin: 0 auto;\n        font-family: Tahoma, Verdana, Arial, sans-serif;\n    }\n&lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;\n&lt;p&gt;If you see this page, the nginx web server is successfully installed and\nworking. Further configuration is required.&lt;/p&gt;\n\n&lt;p&gt;For online documentation and support please refer to\n&lt;a href=\"http://nginx.org/\"&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;\nCommercial support is available at\n&lt;a href=\"http://nginx.com/\"&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>All the containers attached to the default bridge network can talk to each other.</p> <p>What if we want to reach the service running in the container using the local network on the host? </p> <p>Try the following command:</p> <p><pre><code>curl http://127.0.0.1:80\n</code></pre> It won't work... you will get: <code>curl: (7) Failed to connect to 127.0.0.1 port 80: Connection refused</code>...</p> <p>We need to publish the service port in the container to a port on our local network. This can be done using the <code>--publish</code> option (or <code>-p</code>) of the <code>docker container run</code> command. The correct syntax is:</p> <pre><code>--publish &lt;host port&gt;:&lt;container port&gt;\n</code></pre> <p>So let's start another container with this option:</p> <pre><code>docker container run -d --name nginx2 -p 80:80 nginx\n</code></pre> <p>Look at the different description of the two containers:</p> CommandOutput <pre><code>docker ps\n</code></pre> <pre><code>CONTAINER ID   IMAGE     COMMAND                  CREATED          STATUS          PORTS                               NAMES\n8d5609a40033   nginx     \"/docker-entrypoint.\u2026\"   35 seconds ago   Up 33 seconds   0.0.0.0:80-&gt;80/tcp, :::80-&gt;80/tcp   nginx2\n2f03f1f2cd10   nginx     \"/docker-entrypoint.\u2026\"   2 hours ago      Up 2 hours      80/tcp                              nginx\n</code></pre> <p>We can see here that the container port 80 is mapped on the host port 80 (<code>0.0.0.0:80-&gt;80/tcp, :::80-&gt;80/tcp</code>).</p> <p>As before, the command <code>docker container inspect</code> provides further information:</p> <pre><code>...\n        \"NetworkSettings\": {\n            \"Bridge\": \"\",\n            \"SandboxID\": \"c66c74726ef8185887d6057d9efd1a4870f0b4b77543213d3bb4fe80db2bd48b\",\n            \"HairpinMode\": false,\n            \"LinkLocalIPv6Address\": \"\",\n            \"LinkLocalIPv6PrefixLen\": 0,\n            \"Ports\": {\n                \"80/tcp\": [\n                    {\n                        \"HostIp\": \"0.0.0.0\",\n                        \"HostPort\": \"80\"\n                    },\n                    {\n                        \"HostIp\": \"::\",\n                        \"HostPort\": \"80\"\n                    }\n                ]\n            },\n...\n</code></pre> <p>Now we can verify that our service is reachable on port 80 of our local network running the following command from the host:</p> <pre><code>curl http://127.0.0.1:80\n</code></pre> <p>Indeed you can reach your service also from outside using the IP of your host. If the inbound connectivity on port 80 is ensured by the firewall rules, you can connect to the nginx service using the browser on your local workstation.</p> <p> </p>"},{"location":"networking/networking/#using-a-user-defined-bridge-network","title":"Using a user-defined bridge network","text":"<p>In the previous example we have seen that any container you run will be automatically attached to the default bridge network.</p> <p>Tip</p> <p>A user-defined bridge network has some important extra features w.r.t. the default one as described in the official docs on this topic:</p> <ul> <li>Automatic DNS resolution between containers</li> <li>Better isolation</li> <li>Containers can be attached and detached from user-defined networks on the fly</li> <li>Each user-defined network creates a configurable bridge</li> </ul> <p>Now use the <code>docker network create</code> command to create a user-defined bridge network:</p> <p><pre><code>docker network create mynet\n</code></pre> You will get the ID of the newly created network, e.g.:</p> <pre><code>64319187a52ba82fcbff86b348b42c3ac847e5cfb6a2365b123b7de597ff6eee\n</code></pre> <p>List the docker networks: you will see also <code>mynet</code> in the list:</p> CommandOutput <pre><code>docker network ls\n</code></pre> <pre><code>NETWORK ID     NAME      DRIVER    SCOPE\n0aa786b7de5f   bridge    bridge    local\n19747c3d0c9a   host      host      local\n64319187a52b   mynet     bridge    local\n36dc4ef5b900   none      null      local\n</code></pre> <p>We can use the <code>network connect</code> command to attach a container to a network.</p> <p>Tip</p> <p>The syntax for this command is: <code>docker network connect &lt;network identifier&gt; &lt;container identifier&gt;</code></p> <p>Let's connect our first <code>nginx</code> container:</p> <pre><code>docker network connect mynet nginx\n</code></pre> <p>Note that the container was already attached to the default bridge network. Let's inspect the container to get the new networking configuration:</p> CommandOutput <pre><code>docker inspect nginx\n</code></pre> <pre><code>...\n\"Networks\": {\n                \"bridge\": {\n                    \"IPAMConfig\": null,\n                    \"Links\": null,\n                    \"Aliases\": null,\n                    \"NetworkID\": \"0aa786b7de5fbfcd3e18db78511ed544d450bb0ad198cab0244bc8b83d30b514\",\n                   \"EndpointID\": \"c3b64e072f7851e3bf55ba3685fa1fbdec6b9c59d18ae27e5e90a1be5728f54c\",\n                    \"Gateway\": \"172.17.0.1\",\n                    \"IPAddress\": \"172.17.0.2\",\n                    \"IPPrefixLen\": 16,\n                    \"IPv6Gateway\": \"\",\n                    \"GlobalIPv6Address\": \"\",\n                    \"GlobalIPv6PrefixLen\": 0,\n                    \"MacAddress\": \"02:42:ac:11:00:02\",\n                    \"DriverOpts\": null\n                },\n                \"mynet\": {\n                    \"IPAMConfig\": {},\n                    \"Links\": null,\n                    \"Aliases\": [\n                        \"2f03f1f2cd10\"\n                    ],\n                    \"NetworkID\": \"64319187a52ba82fcbff86b348b42c3ac847e5cfb6a2365b123b7de597ff6eee\",\n                    \"EndpointID\": \"a232b9e5a82960e12762b949bc83b3e3bd5357580f937b69cae7097384e9eb69\",\n                    \"Gateway\": \"172.18.0.1\",\n                    \"IPAddress\": \"172.18.0.2\",\n                    \"IPPrefixLen\": 16,\n                    \"IPv6Gateway\": \"\",\n                    \"GlobalIPv6Address\": \"\",\n                    \"GlobalIPv6PrefixLen\": 0,\n                    \"MacAddress\": \"02:42:ac:12:00:02\",\n                    \"DriverOpts\": {}\n                }\n            }\n...\n</code></pre> <p>As you can see, our container has now two interfaces with IPs 172.17.0.2 (on the default network) and 172.18.0.2 (on <code>mynet</code> network).</p> <p>Note that we can also specify the network when we create the container using the <code>--network</code> option. Let's run the following command:</p> <pre><code>docker run -it --net mynet ubuntu bash\n</code></pre> <p>In this way you have created a container that is connected to <code>mynet</code> network. </p> <p>All containers attached to a user-defined network can communicate using their names (automatic DNS resolution)..so you can contact the container <code>nginx</code> directly (you don't need to know its IP).</p> <p>Inside the container, run the commands: </p> <pre><code>apt update\n</code></pre> <pre><code>apt install -y curl\n</code></pre> <p>then run the command <code>curl http://nginx</code> inside the ubuntu container to verify that the automatic DNS resolution is working:</p> <pre><code>root@2f03f1f2cd10:/# curl http://nginx\n&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;Welcome to nginx!&lt;/title&gt;\n&lt;style&gt;\n    body {\n        width: 35em;\n        margin: 0 auto;\n        font-family: Tahoma, Verdana, Arial, sans-serif;\n    }\n&lt;/style&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;h1&gt;Welcome to nginx!&lt;/h1&gt;\n&lt;p&gt;If you see this page, the nginx web server is successfully installed and\nworking. Further configuration is required.&lt;/p&gt;\n\n&lt;p&gt;For online documentation and support please refer to\n&lt;a href=\"http://nginx.org/\"&gt;nginx.org&lt;/a&gt;.&lt;br/&gt;\nCommercial support is available at\n&lt;a href=\"http://nginx.com/\"&gt;nginx.com&lt;/a&gt;.&lt;/p&gt;\n\n&lt;p&gt;&lt;em&gt;Thank you for using nginx.&lt;/em&gt;&lt;/p&gt;\n&lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>Tip</p> <p>In order for the automatic DNS resolution to work you must assign custom names to the containers. Using the randomly generated name will not work.</p>"},{"location":"networking/networking/#lab-challenge","title":"Lab challenge","text":"<p>Goal: create a service based on two containers: </p> <ol> <li>WordPress </li> <li>MariaDB </li> </ol> <p>and then use your web browser to access wordpress on port 8080.</p> <p>Tip</p> <ul> <li>Create a volume <code>db_data</code> to provide persistent storage for the DBMS</li> <li>Create a network</li> <li>Launch MariaDB (image name: <code>mariadb:10.6.4-focal</code>) with container name <code>db</code>, using the previously created volume, attaching it to the previously created network and pass environment variables to the container to configure it</li> <li>Launch WordPress (image name: <code>wordpress:latest</code>) with container name <code>wordpress</code>, and pass environment variables to the container to configure it</li> <li>Use the automatic DNS resolution feature of the previously created network to connect the two containers</li> </ul>"}]}